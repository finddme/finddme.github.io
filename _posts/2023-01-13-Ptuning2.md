---
title: "Prompt-Based Learning 2 | P-Tuning v2: Prompt Tuning Can Be Comparable to Fine-tuning Universally Across Scales and Tasks"
category: Natural Language Processing
tag: NLP
---







* 목차
{:toc}








1. Introduction
PLM은 광범위한 NLU task에 대해 성능을 향상시켰다. 널리 사용되는 방법인 fine-tuning은 PLM의 전체 parameter를 target task에 대해 update한다. fine-tuning은 좋은 성능을 내지만 모든 parameter에 대한 gradients와 optimizer state가 저장된다. 그리고 model의 parameter를 복사하여 가지고 있는 것은 PLM의 크기가 크기 때문에 매우 불편하다.
반면 Prompting은 PLM의 모든 parameter를 freeze시키고 prompt 형태의 query를 LM에 넣는 방식을 사용한다. 감성분석 task에 대해 예를 들어 보면 e.g. "Amazing movie!"라는 sample에 “This movie is [MASK]”라는 prompt를 붙여 PLM이 mask token이 “good”과 “bad” 중 어떤 token의 확률이 높은지 예측하도록 한다. Prompting은 따로 학습을 진행하지 않고 단순히 PLM을 copy하여 사용한다. 하지만 discrete prompting은 fine-tuning에 비해 suboptimal하다.
Prompt tuning은 continuous prompt를 tuning하는 방식이다. Liu et al. (2021); Lester et al. (2021)은 original input sequence의 embedding(continuous prompt)에 대해 추가로 학습을 진행하는 것을 제안하였다. 이 방법론의 경우 학습 시 continuous prompt만 update된다. prompt tuning은 prompting이 다양한 task에서 좋은 성능을 내도록 했지만 model size가 충분히 크지 않을 때(10 billion 이하일 때)는 여전히 fine-tuning보다 성능이 좋지 않다. 특히 QA task와 같은 sequence labeling task에서는 fine-tuning보다 현저히 성능이 떨어진다. 
본 논문의 main contribution은 prompt tuning과 fine-tuning을 다양한 model scale과 NLU task에 대해 경험적으로 비교하는 것이다. 
