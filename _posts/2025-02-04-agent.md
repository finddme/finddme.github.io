
title: "Agent? : AI Agents, Agentic AI, Multi-Agent"
category: LLM / Multimodal
tag: Multimodal
---


 




* 목차
{:toc}













# AI Agent vs.  Agentic AI

## AI Agent
AI Agent는 특정 task를 수행하는 agent이다. AI Agent는 단순하고 반복적인 작업을 자동화하는 데에 적합하지만 자율적인 의사 결정 능력은 없다. 스스로 생각하지 않고 사용자가 지시한 것을 수행하는 가상 도우미 정도의 역할을 할 수 있다. 

## Agentic AI
Agentic AI는 "자율성"에 큰 의의를 두는 인공지능 기반 시스템이라고 볼 수 있다. 특정 목표를 달성하기 위해 스스로 결정을 내리고, 행동을 취하고, 더 나아가 독립적으로 학습(여기서 학습은 모델 학습(training) 개념이 아닌 learning이다. 아래 추가 설명이 있다.)할 수 있다는 시스템이다. 인간의 지속적인 지시 없이도 생각하고, 추론하며, 변화하는 상황에 적응할 수 있는 가상 비서처럼 작동하는 것이다. Agentic AI는 아래 네 가지 단계로 작동한다:

1. 인식(Perception): 데이터를 수집(observation)
2. 추론(Reasoning): 수집된 데이터로 상황 이해
3. 행동(Action): 이해를 바탕으로 무엇을 할지 결정
4. 학습(Learning): 피드백과 경험(저장된 기억)을 통해 시간이 지남에 따라 개선 + 적응

## 비교 표
|  | Agentic AI | AI Agent |
|---|---|---|
| 자율성 수준 | 고도의 자율성, 독립적으로 행동 가능 | 제한된 자율성, 인간의 입력 필요 |
| 목표 지향성 | 목표 중심, 스스로 문제 해결 | 특정 작업 중심, 정해진 지시 수행 |
| 학습 능력 | 지속적으로 학습하고 개선됨 | 학습하지 않거나 정해진 규칙 내에서만 학습 |
| 복잡성 | 복잡하고 동적인 환경 처리 가능 | 더 단순하고 구조화된 작업 처리 |
| 의사결정 과정 | 추론과 분석을 기반으로 결정 | 입력에 대한 미리 프로그래밍된 응답 |
| 환경과의 상호작용 | 주변 환경과 변화에 적극적으로 적응 | 정해진 입력에 반응하지만 적응하지 않음 |
| 변화에 대한 대응성 | 목표와 방법을 자율적으로 변경 | 새로운 상황에 적응하는 능력이 제한됨 |

# Multi-Agent

Muli-Agent에서 말하는 Agent는 초기에는 여러 AI Agent로만 구성된 시스템이었지만 이제 여러 AI Agent와 Agentic AI가 종합적으로 구성된 시스템으로 개념과 정의가 변경되었다. 아래 내용에서 나오는 "Agent"는 모두 Agentic AI이다.

## Agent Architecture

Multi-Agent가 가지는 요소들과 구조는 기본적으로 아래와 같다(각 요소들의 순서나 존재유무는 구현하기 나름이다. 그리고 Agent들은 pipeline 상 계층적일 수도, end-to-end 관계일 수도, 병렬/수평적일 수도 있다. 구현하기 나름이다. ):

### 1. LLM

Agent는 기본적으로 LLM을 기반으로 돌아간다. LLM은 Agent 내에서 텍스트 처리, 상황 및 맥락 이해, 결정 등을 모두 관장한다.

### 2. 계획 설계 및 추론 

LLM을 통해 task를 해결하기 위한 계획을 설계한다. 사용자 입력으로부터 목표를 명확히하고, 해결 방법을 추론하고, 추론 결과를 기반으로 세부 task를 나눈다. 일반적으로 아래와 같은 과정을 거친다.

1. 목표 분석
2. 목표 달성을 위한 해결 단계 정의
3. 단계들의 우선순위 정의
4. 단계들을 수행하며 추가된 정보를 기반으로 계획 조

### 3. Tool use

어떤 시스템과의 상호작용을 통해 task를 수행하거나 지식을 확장시켜주는 부분니다. tool에는 다음과 같은 것들이 존재할 수 있다:

- DB retrieval
- web search
- code 실행 (사전에 정해진 code일 수도 있고 LLM이 생성한 code일 수도 있다.)
- 다른 소프트웨어 시스템과의 상호작용 (다른 어플리케이션을 실행한다든지..)

위 tool들로 인해 Agent는 수행 작업 범위를 확장할 수 있다. 


### 4. Reflection

Reflection 단계는 Agent의 결과를 분석하여 평가하는 것이다. 겉으로 보기에 스스로가 평가하는 것 같아 보여서 Reflection이라고 부르지만 정확하게는 Reflection을 위한 Agent를 따로 두고 output 생성 Agent의 결과에 대한 피드백을 만들어 시스템 목적에 맞는 결과를 생성하는 것이다.

<center><img width="800" src="https://github.com/user-attachments/assets/da69a010-0650-434b-a760-adabeb7ffaee"></center>
<center><em style="color:gray;">Illustrated by Author</em></center><br>


### 5. Agent 고유의 특성 정의

Agent의 성격, 특성, 제약 조건 등을 정의하는 부분으로, 이는 일반적으로 최종 output 생성에 대한 system prompt에 정의한다. 이는 Agent의 행동이 Agent의 목적과 의도에 맞게 반환되는 것에 도움을 준다. 

정의 내용은 아래와 같은 것들이 있을 수 있다.

- Agent가 무엇에 대한 전문가인지, 어떤 목적을 위한 전문가인지 정의
- 말투, 의사소통 스타일 등 정의
- 윤리적 지침
- 기타 조건 (ex) 한국어로만 대답을 생성해야 한다는 조건)

### 6. Memory

AI Agent가 과거의 대화 및 검색 내용을 기억할 수 있도록 저장하는 것이다. 

이는 아래와 같은 측면에서 매우 중요하다:

- 대화 맥락 유지
- 이전 대화로부터 학습
- 꾸준한 성능 향상
- 개인화 응답 제공


## Multi-Agent Collaboration

위와 같은 Multi-Agent를 여러개 붙여서 구현할 수도 있다.

<center><img width="800" src="https://github.com/user-attachments/assets/3ad1b733-de91-4b70-81e3-76b1b6098d70"></center>
<center><em style="color:gray;">https://towardsdatascience.com/ai-agents-from-concepts-to-practical-implementation-in-python-fb26789b1560/</em></center><br>


# Reference

> https://towardsdatascience.com/ai-agents-from-concepts-to-practical-implementation-in-python-fb26789b1560/<br>
> https://medium.com/@vinitgela/the-rise-of-ai-agents-91f93379c0c8<br>
> https://langfuse.com/blog/2024-07-ai-agent-observability-with-langfuse<br>






