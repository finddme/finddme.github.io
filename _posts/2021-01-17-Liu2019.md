---
title: Linguistic Knowledge and Transferability of Contextual Representations(Liu(2019))
category: Natural Language Processing and Linguistics
tag: NLP & Linguistics
---

## 1. Introduction


이번에 살펴볼 논문은 Liu. et al. (2019)의 Linguistic Knowledge and Transferability of Contextual Representations이다. 본 논문에서 제시하는 문제는 아래와 같다:


1. What features of language do these vectors capture, and what do they miss?
2. How and why does **transferability** vary across representation layers in **contextualizers**?
3. How does the choice of pretraining task affect the vectors’ learned linguistic knowledge and transferability? 


- **Transferability**(Transfer Learning(전이 학습)이 얼마나 가능한지): Pre-Trained contexualizer가 특정 Task에 대해 어느정도의 성능을 보이느냐에 따라 전이가 잘 되었는지 아닌지를 판단한다.  
- **Contextualizer**: Sota를 찍은 NLP model에서 중요한 것은 Pre-trained representation이다. 전통적으로 word vector는 static한 word embedding이다. 즉 1 word, 1 vector이다. 이러한 방식은 Glove와 같은 모델에서 사용되었는데, 이러한 모델들은 단어들을 벡터화하는 것에 집중하여 단어 하나하나를 파악했기 때문에 문맥 파악에 취약하다. 최근 연구에서는 이러한 단점을 해결한 Elmo와 같은 모델을 통해 contextual word representations(CWR)을 사용한다. 


> Glove보다 BiLM의 성능이 높기도 하지만 둘의 큰 차이점은 다음과 같다:Glove는 특정 동사를 POS tagging할 때 co-occurrence 빈도가 높은 것을 기준으로 tagging이 진행되는 반면 BiLM은 morphological inflection과 morphological derivation을 구분하여 POS tag가 붙는다.(Peters et al. 2018)


## 2. Model Flow


<center><img width="288" alt="2021-03-06 (1)" src="https://user-images.githubusercontent.com/53667002/110228513-0ea38300-7f45-11eb-9a13-f5052cf94c31.png"></center>

모델의 흐름은 위와 같다. 위 그림은 POS tagging task에 대한 그림이다. 우선 Input Token이 모델에 입력되면 이는 이미 대량의 데이터로 학습된 Pretrained Contextualizer를 통해 feature를 갖는다. 이 feature들은 Probing model을 거쳐서 결과가 나온다. 이렇게 Pretrained model을 사용했을 때가 그렇지 않은 경우보다 더 좋은 성능을 낸다고 하는데, 이러한 방식이 linguistic knowledge를 가져서 높게 나오는 것인지, 어떻게 linguistic knowledge를 가지는지 그리고 어떻게 그 지식들을 전이하는지에 대해 실험해 보는 것이 본 논문의 주요 골자이다.


## 3. Probing Tasks


본 연구에서는 17개의 Probing task를 통해 Linguistic Knowledge를 잘 파악했는지 확인한다. 이 Task들은 크게 Token Labeling, Segmentation, Segmentation로 나뉠 수 있다.


### 3.1 Token Labeling

1\) part-of-speech tagging (POS)


형태소 분석 tagging이다. 이를 통해 CWR이 기본적인 통사를 파악했는지를 평가할 수 있다.


> dataset:  
the Penn Treebank (PTB; Marcus et al., 1993),  
the Universal Dependencies English Web Treebank (UDEWT; Silveira et al., 2014).


2\) CCG supertagging (CCG)

어것은 문장 내 단어들의 통사적 역할에 대한 세부적인 정보를 확인하는 task이다.


> dataset:  
CCGbank (Hockenmaier and Steedman, 2007), a conversion of the PTB into CCG derivations


3\) Syntactic constituency ancestor tagging

이 task의 경우 문장을 넣었을 때 문장 내에서 특정 단어가 어떤 단어에 대해 Parent인지, GParent인지, GGParent인지를 파악하는 것이다. 이를 통해 모델이 계층적 통사구조를 작 파악했는지 알 수 있다.


> dataset:  
phrasestructure tree (from the PTB)


어떤 문장이 입력되었을 때 문장 내의 단어들을 트리로 그렸을 때,


<center><img width="154" alt="2021-03-06 (2)" src="https://user-images.githubusercontent.com/53667002/110228593-b456f200-7f45-11eb-897a-b71be36a43f6.png"></center>
