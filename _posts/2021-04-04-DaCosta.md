---
title: Assessing the ability of Transformer-based Neural Models to represent structurally unbounded dependencies(Da Costa.J et al.(2020)
category: Natural Language Processing and Linguistics
tag: NLP & Linguistics
---

## 1. Introduction

본 연구에서는 영어의 장거리 의존문장을 여러 학습 모델에서 어떻게 처리하는지에 대해 실험한다. 장거리 의존 구문이란 자연어가 가지고 있는 sequential 한 속성과 더불어 hierarchical한 속성을 가지고 있다는 대표적인 예시이다. 영어에서 나타나는 대표적인 장거리 의존 구문은 WH-question, Relative clause, Topicalization이다. 장거리 의존 구문에 대한 자세한 설명은 [Long-Distance Dependency](https://finddme.github.io/linguistics(english)/2021/04/04/Longdistance/) 여기에 있다.

장거리 의존 문장과 같이 복잡한 구조를 가진 문장을 잘 파악하지 못하면 아래와 같은 오류를 낼 수 있기 때문에 자연어처리 분야에서의 장거리 의존 구문 처리는 매우 중요하다.

It was the lawyer(s) who I think you said (GAP) was/were upset.  
-> It was the lawyer who I think you said (GAP) was/*were upset.  
-> It was the lawyer(s) who I think you said (GAP) *was/were upset.  

따라서 본 연구에서는 딥러닝 모델들이 다양한 형태의 장거리 의존 구문을 잘 처리하는지 알아보고자 한다.

## 2. LSTM RNNs 



## Reference

> Da Costa.J et al."Assessing the ability of Transformer-based Neural Models to represent structurally unbounded dependencies,"Association for Computational Linguistics.2020
