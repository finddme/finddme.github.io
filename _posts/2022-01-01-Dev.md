
title: NLP Development list
category: Dev Log
tag: NLP
---

<html>
  <head>
    <style type="text/css">
      .line{border-bottom: 1px solid #BDB8C1;}
      .line2{border-bottom: 2px solid #BDB8C1;}
      .line3{border-bottom: 1px solid #BDB8C1; background-color: #F7F7F7;}
      .line4{border-bottom: 2px solid #BDB8C1; background-color: #F7F7F7;}
      table, th, td {
         border:1px solid #BDB8C1;
         background-color: #FFFFFF;
       }
    </style>
   </head>
   <body>
     <table style="border-collapse:collapse">
       <tr>
         <th class="line4" bgcolor="#F8F7F9">Project</th>
         <th class="line2">Summary of the project</th><th class="line2">Related Pages</th>
       </tr>
       <tr>
         <td class="line3"><strong>Model Merge</strong></td>
         <td class="line">
           <strong>[mergekit]</strong>
           <li>base model:
             <ul>
               <li>7.24B급 모델</li>
             </ul>
           </li>
           <li>merge method:
             <ul>
               <li>MOE : 각 모델이 학습한 데이터 분야가 상이할 경우에 사용했음</li>
               <li>dare_ties</li>
               <li>slerp</li>
             </ul>
           </li>
         </td>
         <td class="line">
           <li><a href="https://finddme.github.io/natural%20language%20processing/2023/12/04/Mistral/">Related Paper Review (Mistral)</a></li>
         </td>
       </tr>
       <tr>
         <td class="line3"><strong>LLM instruction tuning + RAG<br>+ Chatbot</strong></td>
         <td class="line">
           <strong>[vLLM RAG + DPO + Qlora]</strong>
           <li>base model:
             <ul>
               <li>Mistral 7B</li>
               <li>SOLAR-10.7B</li>
               <li>Mixtral-8x7B</li>
             </ul>
           </li>
           <strong>[Qlora]</strong>
           <li>base model:
             <ul>
               <li>LLaMa 2 13B</li>
             </ul>
           </li>
         </td>
         <td class="line">
           <li><a href="https://finddme.github.io/natural%20language%20processing/2023/12/04/Mistral/">Related Paper Review (Mistral)</a></li>
           <li><a href="https://finddme.github.io/natural%20language%20processing/2023/10/10/LLMA2/">Related Paper Review (LLaMa 2)</a></li>
<!--            <li><a href="https://github.com/finddme/LLM-Tuning/tree/main/DPO_QLora">DPO + QLora Tune Code</a></li>
           <li><a href="https://github.com/finddme/LLM-Tuning/tree/main/Lora_QLora">Lora/QLora instruction Tune Code</a></li>
           <li><a href="https://github.com/finddme/RAG">RAG with langchain Code</a></li> -->
         </td>
       </tr>
       <tr>
         <td class="line3"><strong>RAG + Chatbot</strong></td>
         <td class="line">
           <li>base model:
             <ul>
               <li>openai gpt-4</li>
               <li>LLaMa 2 13B</li>
             </ul>
           </li>
         </td>
         <td class="line">
           <li><a href="https://finddme.github.io/natural%20language%20processing/2023/10/10/LLMA2/">Related Paper Review (LLaMa 2)</a></li>
<!--            <li><a href="https://github.com/finddme/RAG">RAG with langchain Code</a></li> -->
         </td>
       </tr>
       <tr>
         <td class="line3"><strong>LLM tuning + Chatbot</strong></td>
         <td class="line">
           <strong>[DPO + QLora]</strong>
           <li>base model:
             <ul>
               <li>Mistral 7b → qlora + dpo</li>
               <li>SOLAR-10.7B → qlora + dpo</li>
               <li>Mixtral-8x7B → qlora + dpo</li>
             </ul>
           </li>
           <strong>[Lora/ QLora / Full Fine tune]</strong>
           <li>base model:
             <ul>
               <li>LLaMa 2 13b → qlora</li>
               <li>LLaMa 13b → lora</li>
               <li>polyglot 12.8b → full fine tune / lora</li>
               <li>polyglot 5.8b → lora</li>
               <li>polyglot 3.8b → full fine tune</li>
               <li>polyglot 1.3b → full fine tune</li>
             </ul>
           </li>
         </td>
         <td class="line">
           <li><a href="https://finddme.github.io/natural%20language%20processing/2023/12/04/Mistral/">Related Paper Review (Mistral)</a></li>
<!--            <li><a href="https://github.com/finddme/LLM-Tuning/tree/main/DPO_QLora">DPO + QLora Tune Code</a></li>
           <li><a href="https://github.com/finddme/LLM-Tuning/tree/main/Full_Fine-Tune">Full Fine Tune Code</a></li>
           <li><a href="https://github.com/finddme/LLM-Tuning/tree/main/Lora_QLora">Lora/QLora instruction Tune Code</a></li> -->
           <li><a href="https://finddme.github.io/natural%20language%20processing/2023/10/10/LLMA2/">Related Paper Review (LLaMa 2)</a></li>
<!--            <li><a href="https://github.com/finddme/RAG/blob/main/make_instruction_Data_from_pdf.ipynb">Make Instruction Data from PDF Code</a></li> -->
           <li><a href="https://finddme.github.io/development/2023/03/31/LLM_instruction_tuning/">Dev Log(data collenction + result)</a></li>
         </td>
       </tr>
       <tr>
         <td class="line3"><strong>Domain-Adaptive Pretrain(DAPT),<br> Task-Adaptive Pretrain(TAPT)</strong></td>
         <td class="line">
           <li>base model: 
             <ul>
               <li>BERT</li>
               <li>ELECTRA</li>
             </ul>
           </li>
           <li>applied domains: 
             <ul>
               <li>Bio<br>(NER: General Medical Domain, Breast Cancer EMR,<br>     Colorectal Cancer EMR에 적용)</li>
               <li>Literature<br>(Sentiment Analysis: Literature에 적용)</li>
             </ul>
            </li>
         </td>
         <td class="line">
           <li><a href="https://finddme.github.io/natural%20language%20processing/2022/11/29/DAPT/">Related Paper Review (DAPT)</a></li>
<!--            <li><a href="https://github.com/finddme/Adaptive-PT">Adaptive-PT Code</a></li> -->
           <li><a href="https://finddme.github.io/natural%20language%20processing/2019/11/22/Bert/">Related Paper Review (BERT)</a></li>
           <li><a href="https://finddme.github.io/natural%20language%20processing/2022/11/30/LMsummary/#electra--efficiently-learning-an-encoder-that-classifies-token-replacements-accurately">ELECTRA</a></li>
         </td>
       </tr>
       <tr>
         <td class="line3"><strong>Named Entity Recognition</strong></td>
         <td class="line">
           <li>base model: 
             <ul>
               <li>BERT</li>
               <li>ELECTRA</li>
             </ul>
           </li>
           <li>class num: 
             <ul>
               <li>도메인별 데이터에 따라 상이</li>
             </ul>
           </li>
           <li>applied domains:
             <ul>
               <li>General</li>
               <li>General Medical Domain</li>
               <li>Breast Cancer EMR(Electronic Medical Record)</li>
               <li>Colorectal Cancer EMR(Electronic Medical Record)</li>
             </ul>
           </li>
         </td>
         <td class="line">
           <li><a href="https://finddme.github.io/development/2022/09/24/NER/">Project Details</a></li>
<!--            <li><a href="https://github.com/finddme/NER_electra">NER Code</a></li> -->
           <li><a href="https://finddme.github.io/natural%20language%20processing/2019/11/22/Bert/">Related Paper Review (BERT)</a></li>
           <li><a href="https://finddme.github.io/natural%20language%20processing/2022/11/30/LMsummary/#electra--efficiently-learning-an-encoder-that-classifies-token-replacements-accurately">ELECTRA</a></li>
         </td>
       </tr>
       <tr>
         <td class="line3"><strong>Sentiment Analysis</strong></td>
         <td class="line">
           <li>base model: 
             <ul>
               <li>BERT</li>
               <li>ELECTRA</li>
             </ul>
           </li>
           <li>class num: 
             <ul>
               <li>34 / 7 / 3</li>
             </ul>
           </li>
           <li>applied domains: 
             <ul>
               <li>General</li>
               <li>Literature</li>
             </ul>
            </li>
         </td>
         <td class="line">
           <li><a href="https://finddme.github.io/development/2022/09/25/SentimentAnalysis/">Project Details</a></li>
<!--            <li><a href="https://github.com/finddme/Sentiment_analysis">SA Code</a></li> -->
           <li><a href="https://finddme.github.io/natural%20language%20processing/2019/11/22/Bert/">Related Paper Review (BERT)</a></li>
           <li><a href="https://finddme.github.io/natural%20language%20processing/2022/11/30/LMsummary/#electra--efficiently-learning-an-encoder-that-classifies-token-replacements-accurately">ELECTRA</a></li>
         </td>
       </tr>
   </table>
 </body>
</html>




