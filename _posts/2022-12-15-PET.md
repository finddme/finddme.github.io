---
title: "Prompt-Based Learning 1 | PET(Pattern Exploiting Training), iPET(Iterative Pattern Exploiting Training)(unfinished post)"
category: Natural Language Processing
tag: NLP
---







* 목차
{:toc}









in-context learning을 통해 LM을 학습시키는 것만으로 fine-tuning 없이 downstream task를 풀 수 있는 방법론이 GPT2를 통해 처음으로 제안되었다. 이 방법론을 기반으로 GPT3는 few-shot setting으로도 다양한 task에 대해 fine-tuning 방법론보다 성능이 좋을 수 있다는 것을 증명하였다. 

하지만 GPT와 같이 큰 모델을 학습시킬 수 없기 때문에 GPT보다 상대적으로 작은 bert계열의 LM 뒤에 특정 task를 수행할 layer를 추가하여 fine-tuning하는 방식이 많이 사용된다. 하지만 fine-tuning 학습을 위한 labeled data를 확보하기 위해서는 많은 비용이 든다는 문제가 있다. 이에 따라 in-context learning을 활용하여 Pre-trained LM을 효과적으로 사용하는 다양한 연구들이 진행되었는데, 그 중 최근 많은 관심을 받고 있는 연구가 Prompt based learning이다. 

# Exploiting Cloze Questions for Few Shot Text Classification and Natural Language Inference

## 1. Pattern-Exploiting Training
본 논문에서는 Prompt based learning 기법 중 하나인 PET(Pattern-Exploiting Training)를 소개한다. PET은 BERT 계열의 모델들이 prompt를 활용하여 task를 푸는 방법론을 제안한다. 이 방법론은 in-context learning의 개념을 차용해서 Language Model이 특정 task를 수행할 수 있도록 PVP(Pattern Verbalizer Pair)를 사용하여 Pre-training Task와 동일한 형태, 즉 cloze-style phrase 형태로 문제(input)를 재정의하는(e.g. “the correct answer is __”와 같은 cloze question 붙임) 것이다.

> PET와 유사한 접근법으로는 [LAMA](https://arxiv.org/pdf/1909.01066.pdf)가 있다.

Figure 1은 sentiment classification에 적용한 것이다.

<center><img width="400" src="https://user-images.githubusercontent.com/53667002/207801491-f601b53a-aaa9-4ee1-a8ff-dec57fff9e0b.png"></center>

Pattern-Exploiting Training을 위해서는 PVP(pattern-verbalizer pair)가 필요하다. 아래는 PVP 개념을 수식적으로 풀어 놓은 것이다.

$\text{M : Masked Language Model}$

$\text{V : Vocabulary}$

$\underbar{ }\underbar{ }\underbar{ }\underbar{ } \in \text{V : Mask Token}$

$\text{A : target classification task}$

$\mathcal{L}\text{: a set of labels for our target classification task A}$

$\textbf{x = }\text{(}\text{s}_{1}\text{,...,}\text{s}_{k}\text{) : input sequence for task A}$

$\text{s}_{1}\in\text{V}^{*}$

$\textbf{P}\text{: pattern}$

$\text{P(}\mathrm{x}\text{)}\in\text{V}^{*}\text{: takes }\mathrm{x}\text{ as input and outputs a phrase or sentence}$

$\mathit{v}\text{ : verbalizer}$

$\mathcal{L}\rightarrow \text{V : verbalizer maps each label to a word from {M}'s vocabulary}$

$\text{(P,}\mathit{v}\text{) : pattern-verbalizer pair}\mathbf{(PVP)}$

위 수식을 보면 A는 target classification task, x는 task A에 대한 input이고 그 input은 phrase s로 구성되어 있다. 그리고 phrase s를 이용하여 문제를 변형하는 것을 Pattern이라고 한다. 

> 본 논문에서는 pattern을 manual하게 만들어내지만 pattern을 모델을 통해 생성해 내는 연구들도 이후 많이 진행되었다. 

<center><img width="200" src="https://user-images.githubusercontent.com/53667002/207803433-a43a49d8-73fa-46cb-b05d-a975c5d79ec4.png"></center>

위와 같이 input phrase a와 b 자체는 유지하면서 mask를 적절히 삽입하여 pattern을 만든다. 아래는 그 예시이다.

<center><img width="200" src="https://user-images.githubusercontent.com/53667002/207803532-a5e13cb0-c66d-46a8-8f34-3d45cf113a4c.png"></center>

<center><img width="200" src="https://user-images.githubusercontent.com/53667002/207803601-f15ce492-d25d-468f-874d-92798e135425.png"></center>

그 다음으로 M은 Language Model, L은 classification task의 label, V는 M의 vocab이다. L(label)을 M(LM)의 V(vocab)내에 있는 자연스러운 token으로 대체하는 mapping function을 v(verbalizer)라고 한다. 

task A를 풀기 위해 pattern에 masking된 부분에 들어갈 자연스러운 token을 예측하는 방식으로 task를 변형시키게 되는데 이때 P(pattern)와 v(verbalizer)는 서로 종속되기 때문에 pattern-verbalizer pair, 즉 PVP(P,v)라고 한다.

### 1.1 PVP Training and Inference 

PVP를 활용한 Inference는 MLM을 통해 전체 vocab에 대한 logit을 구한 이후 verbalizer를 통해 선정한 특정 token에 대해서만 softmax를 수행하는 방식으로 이루어진다. 

이 과정을 수식적으로 설명하도록 하겠다. MLM이 masked position에 할당한 tokend을 w 그리고 mask token을 포함한 sequnece를 z라고 했을 때, MLM에 넣은 후 나온 결과를 $\text{M(}\mathit{w}\mid \text{x)}$ 이렇게 표현했을 때, PVP를 통해 변형한 문제를 MLM에 넣은 후 나온 logit을 수식화하면 아래와 같다.
