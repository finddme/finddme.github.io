---
title: "Prompt-Based Learning 1 | PET(Pattern Exploiting Training), iPET(Iterative Pattern Exploiting Training)"
category: Natural Language Processing
tag: NLP
---







* 목차
{:toc}









in-context learning을 통해 LM을 학습시키는 것만으로 fine-tuning 없이 downstream task를 풀 수 있는 방법론이 GPT2를 통해 처음으로 제안되었다. 이 방법론을 기반으로 GPT3는 few-shot setting으로도 다양한 task에 대해 fine-tuning 방법론보다 성능이 좋을 수 있다는 것을 증명하였다. 

하지만 GPT와 같이 큰 모델을 학습시킬 수 없기 때문에 GPT보다 상대적으로 작은 bert계열의 LM 뒤에 특정 task를 수행할 layer를 추가하여 fine-tuning하는 방식이 많이 사용된다. 하지만 fine-tuning 학습을 위한 labeled data를 확보하기 위해서는 많은 비용이 든다는 문제가 있다. 이에 따라 in-context learning을 활용하여 Pre-trained LM을 효과적으로 사용하는 다양한 연구들이 진행되었는데, 그 중 최근 많은 관심을 받고 있는 연구가 Prompt based learning이다. 

# Exploiting Cloze Questions for Few Shot Text Classification and Natural Language Inference

## 1. Pattern-Exploiting Training
본 논문에서는 Prompt based learning 기법 중 하나인 PET(Pattern-Exploiting Training)를 소개한다. PET은 BERT 계열의 모델들이 prompt를 활용하여 task를 푸는 방법론을 제안한다. 이 방법론은 in-context learning의 개념을 차용해서 Language Model이 특정 task를 수행할 수 있도록 PVP(Pattern Verbalizer Pair)를 사용하여 Pre-training Task와 동일한 형태, 즉 cloze-style phrase 형태로 문제(input)를 재정의하는(e.g. “the correct answer is __”와 같은 cloze question 붙임) 것이다.

> PET와 유사한 접근법으로는 [LAMA](https://arxiv.org/pdf/1909.01066.pdf)가 있다.

Figure 1은 sentiment classification에 적용한 것이다.

<center><img width="400" src="https://user-images.githubusercontent.com/53667002/207801491-f601b53a-aaa9-4ee1-a8ff-dec57fff9e0b.png"></center>

Pattern-Exploiting Training을 위해서는 PVP(pattern-verbalizer pair)가 필요하다. 아래는 PVP 개념을 수식적으로 풀어 놓은 것이다.


$\text{M : Masked Language Model}$

$\text{V : Vocabulary}$

$\underbar{ }\underbar{ }\underbar{ }\underbar{ }\in\text{V : Mask Token}$

$\text{A : target classification task}$

$\mathcal{L}\text{: a set of labels for our target classification task A}$

$\textbf{x}\text{= (}\text{s}_{1}\text{,}\cdots\text{,}\text{s}_{k}\text{) : input sequence for task A}$

$\text{s}_{1}\in\text{V}^{*}$

$\textbf{P}\text{: pattern}$

$\text{P(}\mathrm{x}\text{)}\in\text{V}^{*}\text{: takes }\mathrm{x}\text{ as input and outputs a phrase or sentence}$

$\mathit{v}\text{ : verbalizer}$

$\mathcal{L}\rightarrow \text{V : verbalizer maps each label to a word from {M}'s vocabulary}$

$\text{(P,}\mathit{v}\text{) : pattern-verbalizer pair}\mathbf{(PVP)}$


\begin{matrix}
\text{M : Masked Language Model}\\ 
\end{matrix}

\begin{matrix}
\text{V : Vocabulary}\\
\end{matrix}

\begin{matrix}
\underbar{ }\underbar{ }\underbar{ }\underbar{ }\in\text{V : Mask Token}\\
\end{matrix}

\begin{matrix}
\text{A : target classification task}\\
\end{matrix}

\begin{matrix}
\mathcal{L}\text{: a set of labels for our target classification task A}\\
\end{matrix}

\begin{matrix}
\textbf{x}\text{= (}\text{s}_{1}\text{,}\cdots\text{,}\text{s}_{k}\text{) : input sequence for task A}\\
\end{matrix}

\begin{matrix}
\text{s}_{1}\in\text{V}^{*}\\
\end{matrix}

\begin{matrix}
\textbf{P}\text{: pattern}\\
\end{matrix}

\begin{matrix}
\text{P(}\mathrm{x}\text{)}\in\text{V}^{*}\text{: takes }\mathrm{x}\text{ as input and outputs a phrase or sentence}\\
\end{matrix}

\begin{matrix}
\mathit{v}\text{ : verbalizer}\\
\end{matrix}

\begin{matrix}
\mathcal{L}\rightarrow \text{V : verbalizer maps each label to a word from {M}'s vocabulary}\\
\end{matrix}

\begin{matrix}
\text{(P,}\mathit{v}\text{) : pattern-verbalizer pair}\mathbf{(PVP)}\\
\end{matrix}

위 수식을 보면 A는 target classification task, x는 task A에 대한 input이고 그 input은 phrase s로 구성되어 있다. 그리고 phrase s를 이용하여 문제를 변형하는 것을 Pattern이라고 한다. 

> 본 논문에서는 pattern을 manual하게 만들어내지만 pattern을 모델을 통해 생성해 내는 연구들도 이후 많이 진행되었다. 

<center><img width="200" src="https://user-images.githubusercontent.com/53667002/207803433-a43a49d8-73fa-46cb-b05d-a975c5d79ec4.png"></center>

위와 같이 input phrase a와 b 자체는 유지하면서 mask를 적절히 삽입하여 pattern을 만든다. 아래는 그 예시이다.

<center><img width="300" src="https://user-images.githubusercontent.com/53667002/207803532-a5e13cb0-c66d-46a8-8f34-3d45cf113a4c.png"></center>

<center><img width="300" src="https://user-images.githubusercontent.com/53667002/207803601-f15ce492-d25d-468f-874d-92798e135425.png"></center>

그 다음으로 M은 Language Model, L은 classification task의 label, V는 M의 vocab이다. L(label)을 M(LM)의 V(vocab)내에 있는 자연스러운 token으로 대체하는 mapping function을 $\mathit{v}$(verbalizer)라고 한다. 

task $\mathit{A}$를 풀기 위해 pattern에 masking된 부분에 들어갈 자연스러운 token을 예측하는 방식으로 task를 변형시키게 되는데 이때 $\text{P}$(pattern)와 v(verbalizer)는 서로 종속되기 때문에 pattern-verbalizer pair, 즉 PVP$\text{(P,}\mathit{v}\text{)}$라고 한다.

### 1.1 PVP Training and Inference 

PVP를 활용한 Inference는 MLM을 통해 전체 vocab에 대한 logit을 구한 이후 verbalizer를 통해 선정한 특정 token에 대해서만 softmax를 수행하는 방식으로 이루어진다. 

이 과정을 수식적으로 설명하도록 하겠다. MLM이 masked position에 할당한 token을 $\mathit{w}$ 그리고 mask token을 포함한 sequnece를 $\mathit{z}$라고 했을 때, MLM에 넣은 후 나온 결과를 $\text{M(}\mathit{w}\mid \text{x)}$ 이렇게 표현했을 때, PVP를 통해 변형한 문제를 MLM에 넣은 후 나온 logit을 수식화하면 아래와 같다.

<center><img width="300" src="https://user-images.githubusercontent.com/53667002/207806270-baa24284-a177-47f0-ab52-2e24ede81180.png"></center>

그리고 이걸 softmax 함수에 넣은 것은 아래 수식이다.

<center><img width="300" src="https://user-images.githubusercontent.com/53667002/207807077-f8e208f7-7281-4bb8-b0ea-3ec7852f103e.png"></center>

### 1.2 Auxiliary Language Modeling
이 방법론은 PVP에 대해 PLM을 finetune하는 것이라 볼 수 있다, 즉 MLM에 대해 추가 학습을 수행하는 것이라 할 수 있다. 그렇기 때문에 catastrophic forgetting이 발생할 수 있는데 저자는 g language modeling을 auxiliary task로 활용함으로써 해결하였다. 이를 수식화 하면 아래와 같다.

<center><img width="300" src="https://user-images.githubusercontent.com/53667002/207809087-616de86b-ef96-437c-9fea-04e52bcc3837.png"></center>

$$\text{L}_{ce}$$ 
는 cross-entropy loss로, pattern exploit training에 대한 loss이고, $\text{L}_{MLM}$은 기존 LM이 masked language modeling task에 대해 학습한 loss이다. 기존에 학습된 MLM을 추론에 바로 사용할 수도 있지만 추가적인 학습을 진행할 때에는auxiliary LM loss를 부가하여 사용하면 좋다고 한다.

> 저자는 실험을 통해 $\alpha=\text{10}^{-4}$일 때 좋은 성능을 보이는 것을 발견했다고 한다. 

### 1.3 Combining PVPs

여러 개의 PVP 학습 결과를 combining하여 사용하는 것이 pattern exploit training이다.

PVP를 활용한 접근에서 중요한 것은 어떤 PVP가 해당 task에 잘 맞는지 알아내는 건데, 이 문제를 해결하기 위해 본 논문에서는 knowledge distillation과 유사한 전략을 사용하였다.

> knowledge distillation : 미리 잘 학습된 큰 모델(Teacher network)의 지식을 증류하여 실제로 사용하고자 하는 작은 모델(Student network)로 transfer하는 것

task A에 대해 여러 PVP를 사용하는 과정을 살펴보겠다.

$\mathcal{P}\text{: set of PVP}$

$\text{M}_{p}\text{: Language Model}$

$\mathcal{M}\text{: ensemble of finetuned model}$

$\mathcal{M}\text{= M}_{p}\mid \mathbf{p}\in\mathcal{P}$

<center><img width="300" src="https://user-images.githubusercontent.com/53667002/207809705-fbc5cc6b-19d1-434e-8b15-f70a83f7392c.png"></center>

$\text{M}_{p}$(LM)에 대해 $\mathbf{p}$(pattern)을 받아서 $\mathcal{M}$(ensemble of finetuned model)을 만든다. 이때 2.1에서 언급한 logit에 가중치$\mathit{w}\mathbf{(p)}$를 줘서 새로운 logit을 계산한다. (가중치는 1을 주어 가중평균을 낼 수도 있고 train 이전의 acc를 쓸 수도 있다고 한다.)

> 일반적으로 ensemble할 때 새로운 logit을 만들기 위해 voting방식을 사용하는데 여기에서는 가중치를 줘서 새로운 logit을 만들었다. 
아래 그림은 pattern exploiting training process를 도식화한 것이다. 

<center><img width="400" src="https://user-images.githubusercontent.com/53667002/207809944-08b997c3-b58f-4e0d-8aff-a74e4309d372.png"></center>

$\tau \text{: training dataset}$

$\mathcal{D}\text{: unlabeled data}$

(1) 초기 trainset($\tau$)는 ensemble될 PLM($\text{M}$)에 들어간다.

(2) 각 모델들은 unlabeled data($\mathcal{D}$)에 대해 추론을 하고, ensemble해서 soft-labeled dataset($\tau_{c}$)로 만든다.

(3) soft-labeled dataset($\tau_{c}$)을 $\mathit{C}$(classifier)에 넣어 학습시킨다.

> soft label vs hard label
> 
> soft label은 확률을 사용하여 분류된 것으로, 하나의 데이터가 여러 클래스에 해당할 수 있다.
> 
> hard label은 하나의 데이터가 하나의 클래스로 분류되는 것이다.

### 1.4 Iterative PET (iPET)

<center><img width="800" src="https://user-images.githubusercontent.com/53667002/207810117-002c9d1e-c05f-4d35-ba91-aaaf9eaa766a.png"></center>

앞서 소개한 모든 개별 모델을 distilling을 하여 single classifier $\mathit{C}$로 knowledge를 넘기는 것은 각 모델들이 서로에 대해 모른다는 것을 의미한다. 어떤 pattern이 다른 pattern보다 좋지 않은지 모르기 때문에 final model인 $\mathit{C}$에는 많은 mislabeled examples가 포함된다. 이러한 문제를 해결하기 위해 서로 다른 pattern에 대해 학습한 독립적인 LM($\text{M}$)들이 상호작용할 수 있도록 앞서 설명한 pattern exploiting training process를 반복하는 iPET이 제안되었다. iPET은 trainset($\tau$)을 PLM($\text{M}$)에 넣어 학습시키고 unlabeled data($\mathcal{D}$)에 대해 추론을 하면 거기에 labeling이 된 새로운 data($\tau$)가 만들어지는 것을 반복한다. 

## 2. Experiments and Result 1

본 연구의 실험은 RoBERTa large를 기반으로 다양한 dataset에 대해 실험을 진행하였다. 아래는 실험 결과이다.  PET와 iPET가 대부분 좋은 성능을 내는 것을 확인할 수 있다.

<center><img width="800" src="https://user-images.githubusercontent.com/53667002/207810316-8a4d2fa1-eb5d-4341-86d8-93543f657c95.png"></center>

아래는 data augmentation에 의존하는 semi-supervised learning 중 sota를 기록한 UDA와 MixText와 비교한 결과이다. 

<center><img width="400" src="https://user-images.githubusercontent.com/53667002/207810374-60ad8b27-ecb8-4a58-b56c-548753fe2f29.png"></center>

# It’s Not Just Size That Matters: Small Language Models Are Also Few-Shot Learners

## 3. PET with Multiple Masks

PET 방법론의 한계점 중 하나는 verbalizer($\mathit{v}$)가 single token에 대해서만 mapping된다는 것이다. 이는 여러 task를 수행할 수 없게 한다. 즉, 정답이 single token이지 않을 수 있다. 예를 들어 아래 예시처럼 vocab에 “terrible”이 “terri##”+”##ble”로 있을 수도 있다. 그래서 이러한 경우를 위해 mask를 여러 개 마련해 놓고 확률값이 높은 순서대로 mask를 채워 나가 token을 완성하는 방법을 제안하였다.

<center><img width="400" src="https://user-images.githubusercontent.com/53667002/207810531-f29f807c-8163-4d9f-b35f-331527277d4a.png"></center>

## 4. Experiments and Result 2

본 논문의 실험은 PET의 성능을 GPT3와 비교하기 위해 ALBERT-xxlarge-v2를 기반으로 다양한 SuperGLU 대해 진행되었다. few shot setting하에(data 32개) Figure 1과 같이 parameter 수가 월등히 많은 GPT3보다 대체적으로 좋은 성능을 보였다.


<center><img width="800" src="https://user-images.githubusercontent.com/53667002/207810642-cfc82796-3354-48a6-b32b-f9da72a07485.png"></center>


<center><img width="400" src="https://user-images.githubusercontent.com/53667002/207810692-5a32cd91-1db4-4bbb-8b4f-90e1c5bc44bd.png"></center>

# Reference

> Timo Schick, Hinrich Schütze. "Exploiting Cloze Questions for Few Shot Text Classification and Natural Language Inference,"EACL2021

> Timo Schick, Hinrich Schütze. "It's Not Just Size That Matters: Small Language Models Are Also Few-Shot Learners,"NAACL2021

> https://github.com/timoschick/pet#-train-your-own-pet

> Pengfei Liu, Weizhe Yuan, Jinlan Fu, Zhengbao Jiang, Hiroaki Hayashi, Graham Neubig. "Pre-train, Prompt, and Predict: A Systematic Survey of Prompting Methods in Natural Language Processing,"(https://arxiv.org/pdf/2107.13586v1.pdf)


