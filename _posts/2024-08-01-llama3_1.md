---
title: "LLaMa 3.1"
category: LLM / Multimodal
tag: Multimodal
---







* 목차
{:toc}










# LLaMa 3.1
Llama 3.1 모델을 INT4로 성공적으로 양자화
context length를 128K로 확장, 8개 언어를 지원
Llama 3.1 405B는 최초 frontier-level open source. 지금까지 open source LLM은 closed source LLM에 비해 성능이 좋지 않았지만 LLaMa 3.1 405B는  closed source model에 견줄만한 성능을 보인다.
reference system을 포함하고 있다. 

# INT4 Performance

Meta팀은 Llama-3.1 모델들(405B, 70B, 8B)의 가중치를 INT4 데이터 유형으로 양자화하는 데 성공하였다. parameter당 bits를 16에 4로 줄임으로써 disk size와 GPU memory 요구량을 75% 감소시키며 성능 수준은 그대로 유지하였다.
이로 인해 405B 모델의 경우, 일반적으로 두 개의 8x80GB GPU 노드가 필요하지만 이제 A100이나 H100 GPU를 사용하는 경우 단 4개의 GPU만으로도 단일 서버에서 실행할 수 있게 되었다.
이는 배포 비용을 약 4배나 줄이는 성과이다.

Llama-3.1–405B의 경우, OpenLLM benchmark에서 INT4 버전은 평균 86.47점을, unquantized 버전은 86.63을 기록하여 두 버전 간의 성능 차이가 매우 작은 것으로 확인하였다.

Llama-3.1–70B 또한 INT4 버전의 경우 78.54점을, unquantized model은 78.67점을 기록하여 양자화 전 후 모델간의 성능 차이가 크지 않았다. 하지만 8B는 unquantized 67.57,  INT4 69.32로 70B와 405B에 비해서는 차이를 보이지만 이정도 차이는 disk size와 GPU memory 75% 감소와 같은 효율성 향상을 고려할 때 충분히 수용할 만한 수준이다.
