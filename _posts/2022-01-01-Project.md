---
title: NLP Project list
category: Project
tag: NLP
---

<html>
  <head>
    <style type="text/css">
      .line{border-bottom: 1px solid #BDB8C1;}
      .line2{border-bottom: 2px solid #BDB8C1;}
      .line3{border-bottom: 1px solid #BDB8C1; background-color: #F7F7F7;}
      .line4{border-bottom: 2px solid #BDB8C1; background-color: #F7F7F7;}
      table, th, td {
         border:1px solid #BDB8C1;
         background-color: #FFFFFF;
       }
    </style>
   </head>
   <body>
     <table style="border-collapse:collapse">
       <tr>
         <th class="line4" bgcolor="#F8F7F9">Project</th>
         <th class="line2">Summary of the project</th><th class="line2">Related Pages</th>
       </tr>
       <tr>
         <td class="line3"><strong>Sentiment Analysis</strong></td>
         <td class="line">
           <li>base model: 
             <ul>
               <li>BERT</li>
               <li>ELECTRA</li>
             </ul>
           </li>
           <li>class num: 
             <ul>
               <li>34 / 7 / 3</li>
             </ul>
           </li>
           <li>applied domains: 
             <ul>
               <li>General</li>
               <li>Literature</li>
             </ul>
            </li>
         </td>
         <td class="line">
           <li><a href="https://finddme.github.io/development/2022/09/25/SentimentAnalysis/">Project Details</a></li>
           <li><a href="https://github.com/finddme/Sentiment_analysis">SA Code</a></li>
           <li><a href="https://finddme.github.io/natural%20language%20processing/2019/11/22/Bert/">Related Paper Review (BERT)</a></li>
           <li><a href="https://finddme.github.io/natural%20language%20processing/2022/11/30/LMsummary/#electra--efficiently-learning-an-encoder-that-classifies-token-replacements-accurately">ELECTRA</a></li>
         </td>
       </tr>
       <tr>
         <td class="line3"><strong>Named Entity Recognition</strong></td>
         <td class="line">
           <li>base model: 
             <ul>
               <li>BERT</li>
               <li>ELECTRA</li>
             </ul>
           </li>
           <li>class num: 
             <ul>
               <li>도메인별 데이터에 따라 상이</li>
             </ul>
           </li>
           <li>applied domains:
             <ul>
               <li>General</li>
               <li>General Medical Domain</li>
               <li>Breast Cancer EMR(Electronic Medical Record)</li>
               <li>Colorectal Cancer EMR(Electronic Medical Record)</li>
             </ul>
           </li>
         </td>
         <td class="line">
           <li><a href="https://finddme.github.io/development/2022/09/24/NER/">Project Details</a></li>
           <li><a href="https://github.com/finddme/NER_electra">NER Code</a></li>
           <li><a href="https://finddme.github.io/natural%20language%20processing/2019/11/22/Bert/">Related Paper Review (BERT)</a></li>
           <li><a href="https://finddme.github.io/natural%20language%20processing/2022/11/30/LMsummary/#electra--efficiently-learning-an-encoder-that-classifies-token-replacements-accurately">ELECTRA</a></li>
         </td>
       </tr>
       <tr>
         <td class="line3"><strong>Domain-Adaptive Pretrain(DAPT),<br> Task-Adaptive Pretrain(TAPT)</strong></td>
         <td class="line">
           <li>base model: 
             <ul>
               <li>BERT</li>
               <li>ELECTRA</li>
             </ul>
           </li>
           <li>applied domains: 
             <ul>
               <li>Bio<br>(NER: General Medical Domain, Breast Cancer EMR,<br>     Colorectal Cancer EMR에 적용)</li>
               <li>Literature<br>(Sentiment Analysis: Literature에 적용)</li>
             </ul>
            </li>
         </td>
         <td class="line">
           <li><a href="https://finddme.github.io/natural%20language%20processing/2022/11/29/DAPT/">Related Paper Review (DAPT)</a></li>
           <li><a href="https://github.com/finddme/Adaptive-PT">Adaptive-PT Code</a></li>
           <li><a href="https://finddme.github.io/natural%20language%20processing/2019/11/22/Bert/">Related Paper Review (BERT)</a></li>
           <li><a href="https://finddme.github.io/natural%20language%20processing/2022/11/30/LMsummary/#electra--efficiently-learning-an-encoder-that-classifies-token-replacements-accurately">ELECTRA</a></li>
         </td>
       </tr>
       <tr>
         <td class="line3"><strong>LLM instruction tuning + Chatbot</strong></td>
         <td class="line">
           <li>base model:
             <ul>
               <li>llama 2 13b → lora</li>
               <li>llama 13b → lora</li>
               <li>polyglot 12.8b → full fine tune / lora</li>
               <li>polyglot 5.8b → lora</li>
               <li>polyglot 3.8b → full fine tune</li>
               <li>polyglot 1.3b → full fine tune</li>
             </ul>
           </li>
         </td>
         <td class="line">
           <li><a href="https://finddme.github.io/development/2023/03/31/LLM_instruction_tuning/">Dev Log(data collenction + result)</a></li>
           <li><a href="https://github.com/finddme/LLM-Instruction-Tuning">Instruction tuning Code</a></li>
           <li><a href="https://github.com/finddme/RAG/blob/main/make_instruction_Data_from_pdf.ipynb">Make Instruction Data from PDF Code</a></li>
           <li><a href="https://finddme.github.io/natural%20language%20processing/2023/10/10/LLMA2/">Related Paper Review (LLAMA 2)</a></li>
         </td>
       </tr>
       <tr>
         <td class="line3"><strong>RAG + Chatbot</strong></td>
         <td class="line">
           <li>base model:
             <ul>
               <li>openai gpt-4</li>
               <li>LLAMA 2 13B</li>
             </ul>
           </li>
         </td>
         <td class="line">
           <li><a href="https://finddme.github.io/natural%20language%20processing/2023/10/10/LLMA2/">Related Paper Review (LLAMA 2)</a></li>
           <li><a href="https://github.com/finddme/RAG">RAG with langchain Code</a></li>
         </td>
       </tr>
       <tr>
         <td class="line3"><strong>LLM instruction tuning + RAG<br>+ Chatbot</strong></td>
         <td class="line">
           <li>base model:
             <ul>
               <li>LLAMA 2 13B</li>
             </ul>
           </li>
         </td>
         <td class="line">
           <li><a href="https://finddme.github.io/natural%20language%20processing/2023/10/10/LLMA2/">Related Paper Review (LLAMA 2)</a></li>
           <li><a href="https://github.com/finddme/LLM-Instruction-Tuning">Instruction tuning Code</a></li>
           <li><a href="https://github.com/finddme/RAG">RAG with langchain Code</a></li>
         </td>
       </tr>
   </table>
 </body>
</html>




