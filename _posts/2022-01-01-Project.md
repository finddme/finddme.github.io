---
title: NLP Project list
category: Project
tag: NLP
---

<html>
  <head>
    <style type="text/css">
      .line{border-bottom: 1px solid #BDB8C1;}
      .line2{border-bottom: 2px solid #BDB8C1;}
      .line3{border-bottom: 1px solid #BDB8C1; background-color: #F7F7F7;}
      .line4{border-bottom: 2px solid #BDB8C1; background-color: #F7F7F7;}
      table, th, td {
         border:1px solid #BDB8C1;
         background-color: #FFFFFF;
       }
    </style>
   </head>
   <body>
     <table style="border-collapse:collapse">
       <tr>
         <th class="line4" bgcolor="#F8F7F9">Project</th>
         <th class="line2">Summary of the project</th><th class="line2">Related Pages</th>
       </tr>
       <tr>
         <td class="line3"><strong>Sentiment Analysis</strong></td>
         <td class="line">
           <li>base model: 
             <ul>
               <li>BERT</li>
               <li>ELECTRA</li>
             </ul>
           </li>
           <li>class num: 
             <ul>
               <li>34</li>
               <li>7</li>
               <li>3</li>
             </ul>
           </li>
           <li>applied domains: 
             <ul>
               <li>General</li>
               <li>Literature</li>
             </ul>
            </li>
         </td>
         <td class="line">
           <li><a href="https://finddme.github.io/development/2022/09/25/SentimentAnalysis/">Project Details</a></li>
           <li><a href="https://github.com/finddme/Sentiment_analysis">Code</a></li>
           <li><a href="https://finddme.github.io/natural%20language%20processing/2019/11/22/Bert/">BERT</a></li>
           <li><a href="https://finddme.github.io/natural%20language%20processing/2022/11/30/LMsummary/#electra--efficiently-learning-an-encoder-that-classifies-token-replacements-accurately">ELECTRA</a></li>
         </td>
       </tr>
       <tr>
         <td class="line3"><strong>Named Entity Recognition</strong></td>
         <td class="line">
           <li>base model: 
             <ul>
               <li>BERT</li>
               <li>ELECTRA</li>
             </ul>
           </li>
           <li>class num: 
             <ul>
               <li>도메인별 데이터에 따라 상이</li>
             </ul>
           </li>
           <li>applied domains:
             <ul>
               <li>General</li>
               <li>General Medical Domain</li>
               <li>Breast Cancer EMR(Electronic Medical Record)</li>
               <li>Colorectal Cancer EMR(Electronic Medical Record)</li>
             </ul>
           </li>
         </td>
         <td class="line">
           <li><a href="https://finddme.github.io/development/2022/09/24/NER/">Project Details</a></li>
           <li><a href="https://github.com/finddme/NER_electra">Code</a></li>
           <li><a href="https://finddme.github.io/natural%20language%20processing/2019/11/22/Bert/">BERT</a></li>
           <li><a href="https://finddme.github.io/natural%20language%20processing/2022/11/30/LMsummary/#electra--efficiently-learning-an-encoder-that-classifies-token-replacements-accurately">ELECTRA</a></li>
         </td>
       </tr>
       <tr>
         <td class="line3"><strong>Domain-Adaptive Pretrain(DAPT),<br> Task-Adaptive Pretrain(TAPT)</strong></td>
         <td class="line">
           <li>base model: 
             <ul>
               <li>BERT</li>
               <li>ELECTRA</li>
             </ul>
           </li>
           <li>applied domains: 
             <ul>
               <li>Bio<br>(NER: General Medical Domain, Breast Cancer EMR, Colorectal Cancer EMR에 적용)</li>
               <li>Literature(Sentiment Analysis: Literature에 적용)</li>
             </ul>
            </li>
         </td>
         <td class="line">
           <li><a href="https://finddme.github.io/natural%20language%20processing/2022/11/29/DAPT/">Related Paper Review</a></li>
           <li><a href="https://github.com/finddme/Adaptive-PT">Code</a></li>
           <li><a href="https://finddme.github.io/natural%20language%20processing/2019/11/22/Bert/">BERT</a></li>
           <li><a href="https://finddme.github.io/natural%20language%20processing/2022/11/30/LMsummary/#electra--efficiently-learning-an-encoder-that-classifies-token-replacements-accurately">ELECTRA</a></li>
         </td>
       </tr>
       <tr>
         <td class="line3"><strong>LLM instruction tuning + Chatbot</strong></td>
         <td class="line">
           <li>base model:
             <ul>
               <li>decapoda-research/llama-13b-hf → lora</li>
               <li>openlm-research/open_llama_13b → lora</li>
               <li>EleutherAI/polyglot-ko-12.8b → lora</li>
               <li>EleutherAI/polyglot-ko-5.8b → lora</li>
               <li>EleutherAI/polyglot-ko-3.8b → full fine tune</li>
               <li>EleutherAI/polyglot-ko-1.3b → full fine tune</li>
             </ul>
           </li>
         </td>
         <td class="line">
           <li><a href="https://finddme.github.io/development/2023/03/31/LLM_instruction_tuning/">Dev Log</a></li>
         </td>
       </tr>
       <tr>
         <td class="line3"><strong>RAG + Chatbot</strong></td>
         <td class="line">
           <li>base model:
             <ul>
               <li>openai gpt-4</li>
               <li>hugging face LLAMA 2 13B</li>
             </ul>
           </li>
         </td>
         <td class="line">
           <li><a href="https://finddme.github.io/natural%20language%20processing/2023/10/10/LLMA2/">LLAMA 2</a></li>
         </td>
       </tr>
       <tr>
         <td class="line3"><strong>LLM instruction tuning + RAG<br>+ Chatbot</strong></td>
         <td class="line">
           <li>base model:
             <ul>
               <li>hugging face LLAMA 2 13B</li>
             </ul>
           </li>
         </td>
         <td class="line">
           <li><a href="https://finddme.github.io/natural%20language%20processing/2023/10/10/LLMA2/">LLAMA 2</a></li>
         </td>
       </tr>
   </table>
 </body>
</html>




