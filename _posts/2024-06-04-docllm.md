---
title: "DocLLM: A layout-aware generative language model for multimodal document understanding"
category: Multimodal
tag: Multimodal
---







* 목차
{:toc}











# 1. Introduction

DocLLM은 특정 양식을 갖춘 자료 혹은 각종 청구서를 처리하기 위 모델로, JPMorgan에서 개발하였다. 해당 모델은 아래 그림과 같이 요약될 수 있다.

<center><img width="600" src="https://github.com/finddme/finddme.github.io/assets/53667002/5d962f31-5931-46dd-af7a-c36264659596"></center>
<center><em style="color:gray;">DocLLM: A layout-aware generative language model for multimodal document understanding</em></center><br>

1. 학습에 사용되는 데이터는 OCR을 통해 text token과 그에 대한  bounding box 정보가 포함된 데이터이다. 해당 모델은 문서의 layout 구조를 이해할 때 기존의 Multimodal Model들이 시각 정보를 처리하는 방식과는 달리 image encoder가 아닌 OCR을 통해 얻어진 bounding box 정보를 사용한다. (image encoder를 사용하지 않기 때문에 모델 크기가 타 Multimodal Model에 비하여 작고, 이에 따라 추론 시간도 단축된다.)

2. 해당 모델은  text semantic과 spatial layout 간의 관계를 포착할 때 확장된 attention mecanism을 도입한다. 본 모델은 문서 내 text 와 공간적(spatial) 정보를 각각 따로 처리하기 위해 두 modality 간의 cross-alignment를 포착할 때 classical transformer의 self-attention mechanism을 분해하여 사용한다. 구체적으로, 각 modality에 대한 attention score 뿐만 아니라 두 modality간의 관계를 포착하는 attention score도 계산한다. 

3. 다양한 layout과 문서 내 시각적 정보를 잘 파악하기 위해 사전 학습 과정에서 infill text segment task를 학습한다. infill text segment task는 다양한 layout을 지닌 문서에서 이전 text 정보가 현재 text와 관련 없을 가능성이 있기 때문에 이러한 경우를 파악하기에 적합한 과제이다. 

4. 사전 학습 후에는 네 가지 핵심 문서에 대해 intelligence task에 대한 fine-tuning(instruction-tuning)을 수행한다.

본 연구의 contribution은 아래와 같다:

- visual document를 이해하기 위해 설계된 light-weight LLM 개발
-  text and layout modality 간의 cross-alignment를 위한 분리된 attention mechanism 제안
- 불규칙적인 layout을 효과적으로 파악하기 위한 infilling pre-training objective 도입
- visual document intelligence task 수행을 위해 특수 생성된 instruction-tuning dataset 구축

# 2.  Related Work
## 2.1 LLM Architectures

### Autoregressive Infilling

 autoregressive infilling approach에는 두 가지 방법이 있다. 

 - FIM(fill-in-the-middle): single span 예측
 - GLM(General language
model pretraining with autoregressive blank infilling): multiple span 예측

OpenAI의 FIM approach는 문서를 (prefix, middle, suffix) 이렇게 세 부분으로 나눈다. 나누어진 문서는 (prefix, suffix, middle)로 재구성되어 모델이 middle segment를 예측할 수 있게 한다. 이 과정은 \[PRE], \[SUF] 그리고 \[MID] token을 기준으로 수행된다. 즉, 실제 수행 시 \[MID] token을 예측 시작 기준으로 삼는다. 이와 같은 방법은 autoregressive model이 middle part가 누락된 텍스트를 채우는 방법을 학습하게 한다.

GLM은 multiple span을 채우는 과제이다. 빈칸을 채우기 위해 해당 과제에서는 \[blank_mask]와 \[start_to_fill] 쌍을 사용한다. 


### Disentangled attention

 Disentangled attention은 DeBERTa에서 처음 도입되었다. 해당 mechanism은 token embedding과 relative positional encoding을 합치지 않고 별도로 유지하며, attention weight
를 계산할 때 분리된 matrix를 사용하여 각각 독립적으로 처리한다. 이는 content와 position이 각각 분리된 attention alignment를 학습할 수 있게 하는데, 이것이  NLU benchmark에서 DeBERTa가 RoBERTA-large와 T5를 능가하게 한 지점이라고 알려져 있다.


# 3. DocLLM Framework

<center><img width="600" src="https://github.com/finddme/finddme.github.io/assets/53667002/9ccc9401-871c-47d6-bce8-0e1ecf96e0b3"></center>
<center><em style="color:gray;">DocLLM: A layout-aware generative language model for multimodal document understanding</em></center><br>


## 3.1 Model Architecture



## 3.2 Disentangled Spatial Attention

DocLLM은 text token과 그에 대한 bounding box 정보가 쌍을 이룬 data를 input으로 받는다. 본 모델은 bounding box를 separate hidden vector로 encoding하고 attention mechanism을 네 가지 score로 분해한다: text-to-text, text-to-spatial, spatial-to-text, spatial-to-spatial. 각각의 점수의 균형을 맞추기 위해 projection matrix와 hyperparameter를 사용한다. spatial information에 대한 hidden vector는 layer 전반에 걸쳐 재사용된다.
