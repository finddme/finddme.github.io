---
title: RAG(Retrieval-Augmented Generation)
category: Natural Language Processing
tag: NLP
---







* 목차
{:toc}








# 1. What is RAG?
RAG(Retrieval-Augmented Generation)은 LLM 기반 QA시스템에서 LLM의 hallucination 문제를 완화하고 정보를 효율적이고 정확하게 반환하기 위한 방법론이다. 
RAG은 Indexing-Retrieval-Generation 단계를 통해 사용자로부터 입력된 질문에 대해 답을 반환한다.

1) Indexing
   - 문서(PDF, docx 등)를 chunk로 분절
   - 분절된 chunk를 vector로 encode(indexing)
   - vector DB에 적재
     
2) Retrieval
   - 입력된 질문과 의미 유사도가 높은 Top k의 chunk를 찾는다.
   - Indexing 단계에서 사용된 embedding model과 동일한 모델을 사용하여 사용자 질문을 encoding해야 한다.
     
3) Generation
   - 입력된 질문과 retrieved chunk를 LLM에 함께 입력하여 답변을 생성한다.
  
     아래와 같이 user_message(사용자 질문)과 context(retrieval 결과)를 함께 LLM에 입력하며, context를 참고하여 user_message에 대한 답변을 생성하라는 prompt를 포함시켜 LLM에 입력한다.
     ```
      prompt=f"""
      <|im_start|>system
      You are a helpful assistant chatbot. 
      Write a response that appropriately completes the request, referring to given Context.
      When generating responses, it is crucial to adhere to the following conditions.
      - Do not generate new question. You must respond only to the given question.
      - You should never repeat the same sentence.
      - Do not repeat the questions in your response. 
      - You must answer in Korean Language. Do not use any other languages except Korean.
      Here is context to help:
      context: {context}<|im_end|>
      <|im_start|>user
      {user_message}<|im_end|>
      <|im_start|>assistant
      """  
     ```

RAG은 내부 플로우 구성에 따라 아래 이미지와 같이 크게 3 종류로 나뉜다.

<center><img width="1000" src="https://github.com/finddme/finddme.github.io/assets/53667002/002dd783-0e47-4e1b-847a-c31bc4898693"></center>

## 1.1 Naive RAG

Naive RAG(standard RAG)은 가장 기본적인 RAG이다. 

<center><img width="1000" src="https://github.com/finddme/finddme.github.io/assets/53667002/7bd535bf-efd6-41d5-9461-b47b28bd4400"></center>

### Naive RAG의 문제점

Naive RAG의 각 단계마다 문제점들이 존재한다.

1. Query:
   
   사용자의 질문이 명확하지 않은 경우, similarity search 과정에서 오류가 발생할 수 있다.
   
2. Indexing
   
   1) Parsing: PDF와 같은 비정형 문서 내 이미지 및 표에 담긴 유용한 정보에 대한 추출이 불완전하다.

   2) Chunking: 파일 특성을 고려하지 않고 일률적인 크기로 chunking함으로써 의미상 포함되어야 할 정보가 고정된 size 문제로 잘려 각 chunk에 불완전한 정보가 담겨있을 가능성이 있다.

   3) Indexing: vector db의 indexing 구조가 파일 유형마다 최적화되어 있지 않아 retreival 과정에 부정적인 영향을 미칠 수 있다.

   4) Embedding Model: 임베딩 모델의 semantic representation 성능이 좋지 않을 경우 retreival 과정에 부정적인 영향을 미칠 수 있다.

3. Retrieval
   
   1) 검색된 chunk들과 질문의 관련성이 낮을 가능성이 있다.
 
   2) 여러 검색 알고리즘을 종합적으로 사용할 수 없어 검색 기능이 제한적이다.
   
   3) 검색된 chunk들에 유사한 정보가 중첩되는 경우, LLM이 생성 시 참고할 정보가 제한적이다.

4. Generation
   
   1) 생성모델 특성 상 동일한 질문에 대해 일관적이지 않은 답변이 생성될 수 있다.

   2) 생성 모델의 성능에 따라 새로운 답변을 생성하지 않고 검색된 chunk에 과도하게 의존하는 경우도 있다. 이 경우 chunk를 그대로 반환하기도 한다.

   3) LLM의 문제점을 완화하기 위해 RAG을 적용했지만 여전히 부정확하거나 관련 없는 답변을 생성할 가능성이 있다. 
  

## 1.2 Advanced RAG

Advanced RAG은 Naive RAG에서 Retrieval 앞뒤에 검색 정확도를 높이기 위한 과정이 추가된 RAG이다. 아래 그림에서 파란색 부분이 이에 해당한다.

<center><img width="1000" src="https://github.com/finddme/finddme.github.io/assets/53667002/74c631bc-d917-43c1-a6f1-372cad685242"></center>




