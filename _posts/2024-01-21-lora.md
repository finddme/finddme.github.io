---
title: "Variants of Low-Rank Adaptation : LoRA, DoRA"
category: Natural Language Processing
tag: NLP
---







* 목차
{:toc}








최근 Large Language Model이 많이 나오며 대규모 모델을 효율적으로 학습시킬 수 있는 방법에 대한 연구가 활발히 진행되고 있다. 해당 연구는 주로 LLM tuning 이후의 성능을 더 좋게 하거나 모델을 보다 빠르게 훈련시킬 수 있도록 하는 방향으로 진행되고 있다.  이러한 연구의 대표로는 Low-Rank Adaptation (LoRA)가 있는데 LoRA란, parameter 수를 줄여 LLM을 빠르고 효과적으로 학습시킬 수 있도록 한다. 최근 이와 관련된 연구가 많이 진행되는 만큼 LoRA의 변형들도 많이 나온 상황이다. 

> LLM tuning으로 사용되는 일반적인 방법은 LLM의 일부 layer를 원하는 task에 맞게 학습시키는 것이다.

# LoRA

<center><img width="400" src="https://github.com/finddme/finddme.github.io/assets/53667002/87e0634d-0680-48b7-a751-84cd8c098886"></center>
<center><em style="color:gray;">Low-Rank Adaption (LoRA)</em></center><br>

위 이미지처럼 LoRA는 pre-trained LLM layer의 parameter weight matrix $W$를 frozen 시키고 $W$ 외에 "adapter"라 불리는 두 개의 행렬 A와 B를 추가한다. 추가된 두 행렬은 $W$보다 작다. 예를 들어 $W$의 크기가 $d x d$일 때 A와 B의 크기는 $d x r$과 $r x d$이며, $r$($rank$)은 일반적으로 100 이하의 매우 작은 크기이다. $r$의 크기가 클 수록 더 많은 parameter를 학습시키게 된다. 더 많은 parameter를 학습시킨 다는 것은 더 좋은 성능으로 이어질 가능성이 있지만 학습 시간이 길어진다는 단점이 있다. 

학습이 진행 될 때 frozen된 $W$와 B\*A에 동일한 값을 입력한 후 B\*A의 출력을 original matrix $W$의 출력에 추가한다. 즉, 일부 parameter를 학습시키고 그 출력을 original prediction에 더하여 모델에 영향을 주는 방식으로 작동된다. 처음에 행렬 A는 평균이 0인 랜덤 값들로 구성된다(Random values of mean zero). 즉, 랜덤 변수의 값들이 평균적으로 0을 중심으로 분포된다. 그리고 B는 완전히 0으로 초기화된다. 이와 같은 처리를 통해 adpater 행렬이 original matrix $W$의 출력을 완전 초기부터 변경시키지 않도록 한다. A와 B의 parameter가 적절한 방향으로 tuning될 때 A와 B의 출력이 $W$의 출력에 영향을 미치도록 조정하기 위함이다. 

LoRA는 끝쪽에서만 이루어져야 하는 것은 아니고 neural network 내부의 깊은 layer에도 적용 가능하다.



# DoRA
