---
title: "Prompt-Based Learning 2 | P-tuniung: GPT Understands, Too"
category: Natural Language Processing
tag: NLP
---







* 목차
{:toc}








# 1. Introduction / Motivation

GPT 계열의 모델들은 fine-tuning 방식으로 NLU task를 수행했을 때 bert계열의 모델들보다 좋은 성능을 보이지 않는다. 이는 GPT 계열의 일방향적 특성 때문이라고 알려져 있다. GPT3의 경우에는 적절하게 만든 handcrafted prompt를 통해 NLU task를 풀긴 하지만 best-performing prompt를 handcrafting으로 찾는 것은 사막에서 바늘 찾는 것과 같다. 그리고 pattern을 manual하게 조정하게 되면 pattern(prompt)에 따라 성능 차이가 크다는 문제도 존재한다. Table 1은 prompt에 따라 성능차이가 심한 것을 보여준다.

<center><img width="600" src="https://user-images.githubusercontent.com/53667002/208833410-9cf5c9e5-f445-4984-811b-54b4a9e66a6b.png"></center>

> 그리고 GPT3와 같이 거대한 모델의 치명적인 단점은 poor transferability이다. many-shot setting 하에서fine-tuning을 한다 해도 거대 모델들은 fine-tuning sample을 빠르게 담아내기에 모델 자체가 너무 커서 제대로 되지 않는다.

이러한 이유로 prompt를 자동으로 생성하는 연구들이 진행되었다. 하지만 이들은 모두 이산적인 prompt를 생성하는데 neural network 자체가 continuous하기 때문에 discrete한 정보는 neural network에게 sub-optimal하다. 따라서 본 논문의 저자들은 P-tuning을 제안하며 연속적인 공간에서 prompt를 자동으로 생성하여 GPT계열 모델들의 NLU application 수행문제를 해결하고자 하였다.

> Discrete: token/문자로 이루어져 이산적인 상태
> 
> Continuous: token이 embedding되어 연속적으로 존재하는 상태

본 논문에서는 P-tuning을 이용했을 때 GPT 계열의 모델도 비슷한 크기의 BERT 계열 모델만큼 NLU task를 잘 수행할 수 있다는 것을 보여준다. 그리고 BERT도 p-tuning을 했을 때 fine-tuning보다 성능이 향상되었다고 한다.

BERT와 같이 MLM task를 학습한 모델도 prompt를 활용하여 task를 해결할 수 있는 방법을 제안한 PET, iPET의 경우 labeled data가 많이 필요한 fine-tuning의 문제점을 완화시킬 방법을 제안했지만 두 방법론의 경우에는 unlabeled data가 많이 필요하고, 앞서 언급한 GPT의 prompt 생성과 동일하게 pattern을 manual하게 생성 및 조정해야 한다는 문제와 생성한 prompt가 discrete하다는 문제가 있다. 따라서 BERT 계열의 prompt based learning에서도 p-tuning을 통해 성능 향상이 이루어진 것으로 보인다

<center><img width="600" src="https://user-images.githubusercontent.com/53667002/208816486-97c98012-4a23-4016-9f9b-b81f2fed7110.png"></center>

위 그림은 PET, iPET, AdaPrompt, AutoPrompt와 같이 P-tuning 이전에 선행된 Prompt searching 방식을 표현한 것인데 모두 LM의 loss를 reward로 삼아 prompt generator를 통해 이산적인 prompt를 생성한다. 앞서 말했듯이 이산적인 정보는 neural network에게 sub-optimal하다.

<center><img width="600" src="https://user-images.githubusercontent.com/53667002/208816564-10f03356-6c3c-4384-86c6-f2131e50a49f.png"></center>

P-tuning은 선행 연구들의 문제를 해결하기 위해 위 그림과 같이 bi-LSTM으로 구성된 prompt encoder를 통해 연속적인 공간 내에서 prompt-based learning을 수행한다. 즉, prompt encoder 학습 시 PLM의 전체 weight에 대한 parameter update(fine-tuning) 없이 continuous prompt embedding만 tuning하여 prompt를 생성한다.

# 2. Method: P-tuning

# Reference

> Xiao Liu, Yanan Zheng, Zhengxiao Du, Ming Ding, Yujie Qian, Zhilin Yang, Jie Tang. "GPT Understands, Too,"2021

