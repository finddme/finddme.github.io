---
title: Contextual word representation
category: Natural Language Processing and Linguistics
tag: NLP & Linguistics
---

## 1. Contextual representations of language

language model들의 vector representation방식 변화는 아래와 같다. 

word type들에 대해 pre-trained vector embedding된 word2vec과 Glove가 있다. 아래 수식에서$f_{vocab} : v->h$에서 $f_{vocab}$은 vocabulary가 embedding된다는 것을 나타낸다.

\begin{matrix}
f_{vocab}: v->h
\end{matrix}

FastText와 같은 Subword-informed 방식은 literal character, 즉 음절 자체가 sequence로 embedding되는 것이다. 그래서 앞에 $v_1$이 단어이고 뒤에 있는 $c_1$부터 $c_t$가 character단위로 쪼개진 것이다.

\begin{matrix}
f_{subword} : (v,(c_1, …, c_t) ->h
\end{matrix}

ELMo와 BERT는 특정 문맥에서의 해당 단어의 쓰임이 반영한다. $w_1$부터 $w_n$은 텍스트에 존재하는 word이고, 이것들이 embedding되어서 $h_1$부터 $h_n$이 되는 것이다.

\begin{matrix}
f_{contextual} : (w_1, …, w_N) => (h_1, … h_N)
\end{matrix}

## 2. Beyond “words in context”

strong contextual representation을 위한 model들(CoVe, ELMo, ULMFiT, GPT, BERT, GPT2)의 behavior를 보완하기 위해 강력한 contextual model들이 언어 이해에 중요한 task들을 암시적으로 수행하는 것이 제안된다(syntax, coreference, QA 등).

문맥에서의 단어는 파악했지만, 문장 자체가 지닌 중의성들과 구조적인 중의성 표현들은 어떻게 해결할 것인가에 대한 문제가 남아있다. The chef who ran to the stroe was out of food라는 문장은 중의성을 가진다. 이 문장에는 두 가지 가능성이 존재한다. 음식이 없기 때문에 셰프가 다른 store에 간 것인지 혹은 재료가 다 떨어져서 셰프가 식당으로 돌아온 것인지. 직감적으로는 후자가 맞을 것 같다. 그래서 chef가 was에 걸릴 수 있도록 하는 것이 직관에 맞는 구문분석이다.

> 언어학 지식을 고려한 NLP논문들(Tal Linzen과 John Hewitt의 논문 등)은 대부분 모델의agreement와 관계절 반영을 중요 주제로 삼는다. agreement는 grammatical theory에 있어 중요한 역할을 한다. 따라서 agreement가 설명이 되어야 syntax가 어느정도 맞다고 이론적으로 이야기할 수 있다. 자연어는 sequential한 속성과 hierarchical한 속성이 공존한다. 영어의 장거리 의존 구문은 크게 관계절, wh-question, topicalization이 있다. 그 중에서 syntactic complexity(통사적 복잡도)가 가장 높은 것이 관계절이다. 따라서 자연어가 가지는 단순한 sequential한 속성이 아닌 hierarchical한 속성까지 반영하여 구문을 처리했다고 말할 수 있으려면 agreement와 장거리 의존 구문을 처리할 수 있어야 모델이 English syntax의 어떠한 특성을 반영하고 있다고 말할 수 있다. BERT와 ELMo와 같은 large neural network들이 syntax를 제대로 이해한다면 hierarchical한, in-depth한 syntactic information을 반영할 것이다.

## 3. observational vs. constructive evidence

### 3.1 observational evidence

<center><img width="550" alt="2021-03-27" src="https://user-images.githubusercontent.com/53667002/112973850-b69b1d80-918c-11eb-8c4c-41c5885312db.png"></center>

observational network study는 hand-crafting(직접 input을 넣어서 원하는 대로 나오는지 보는 것)이다. Linzen 논문 같은 경우 수일치가 가능한가에 대한 가능성을 확인하는데, attractor같은 것들이 방해 요소가 된다. 예를 들어 The keys to the cabinet are on the table에서의 The keys와 are사이에 자리한 to the cabinet이 attractor이다. observational study는 model behavior과 data에 대한 질문을 제기할 수 있게 한다. 이는 가설의 혼동 요소 없이 직접적으로 model의 behavior를 보여주기 때문에 매우 유용하다.

### 3.2 constructive evidence 

모델을 학습시킬 때 하나의 특정 현상에 대한 feature들을 찾아서 같이 학습시키는 것이다. 그래서 중간에 나오는 trains on supervised data에서 여러 feature들(syntax나 POS 등) 중에서 하나를 고르는 것인데 이것을 prove라고 하거나 diagnostic classifier라고 한다. 이와 같은 연구의 예시로 Belinkov(2017)가 있는데, 이는 machine translation system에 대한 논문이다. 이 논문에서는 morphology를 기반으로 문장 내에서 feature를 골라 학습시킨다. (각 문장에서의 단어에 어떤 morphological feature들이 있는지를 고른다.) 이 연구에서는 모델의 hidden state에서 각각 encoding되는 정보를 특정한다. 즉, 1-layer nn에 대한 단어 w_i의 morphological 정보 y_i와 parameter값에 대해 모델에서 다음과 같이 encoding되는 것을 제안한다:

\begin{matrix}
y_i \sim 1-layer\,nn (h_i)
\end{matrix}

constructive study는 현상에 대한 구조적인 증거를 줄 수 있기 때문에 유용하다. Hewitt의 논문도 constructive study에 속하며, syntactic node를 가지고 feature를 찾아 그것을 학습시킨다.

## Reference

> https://nlp.stanford.edu/~johnhew/structural-probe.html#the-structural-probe
