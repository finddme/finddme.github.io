---
title: "Vision Language Model : Applications (작성 중)"
category: Multimodal
tag: Multimodal
---







* 목차
{:toc}










Vision Language Model은 이미지와 텍스트를 입력받아 두 데이터를 이애하여 특정 task를 수행하는 모델이다. Vision Language Model이 수행하는 task의 종류는 매우 다양하다.

# 1. Generation Task

## 1.1 Visual Question Answering

<center><img width="400" src="https://github.com/finddme/finddme.github.io/assets/53667002/adc5ce6e-1f21-44e2-9f04-55b4859ad058"></center>
<center><em style="color:gray;">Illustrated by the author</em></center><br>

image (혹은 video)와 해당 image에 대한 질문을 text로 입력받아 text로 질문에 대한 답을 반환하는 task. 

예를 들어 아래 그림에 대해 "저 꽃은 무슨 색인가요?"라는 질문을 하고 "주황색"이라는 답변을 받는 task이다.

<center><img width="200" src="https://github.com/finddme/finddme.github.io/assets/53667002/a129d438-791e-4661-bade-353879b2e8aa"></center>
<center><em style="color:gray;">Openai Image generator</em></center><br>


## 1.2 Visual Captioning and Description

<center><img width="1000" src="https://github.com/finddme/finddme.github.io/assets/53667002/5ed8a4d1-31ee-4417-b3dd-ecaaad4a42ea"></center>
<center><em style="color:gray;">Illustrated by the author</em></center><br>

image에 대한 설명을 생성하는 task. image를 입력 받아 text로 설명을 반환하거나, image와 prompt를 함께 입력 받아 설명을 반환할 수도 있다.

## 1.3 Identifying Objects in Images with Textual Cues

<center><img width="400" src="https://github.com/finddme/finddme.github.io/assets/53667002/386184b4-9ad4-4b59-b4fc-475651426784"></center>
<center><em style="color:gray;">Illustrated by the author</em></center><br>

image와 그에 대한 설명을 입력 받아 설명에 등장한 객체를 이미지 내에서 찾아내는 task. 

예를 들어 아래 그림과 함께 "사람이 물을 마시고 있다" 라는 caption을 입력받으면 입력된 텍스트 정보 내에 등장한 객체("사람" 과 "물")을 이미지 내에서 찾는 task이다. 

<center><img width="400" src="https://github.com/finddme/finddme.github.io/assets/53667002/b190a055-2a3f-4824-bae5-907271a68291"></center>
<center><em style="color:gray;">Openai Image generator</em></center><br>

## 1.4 Visual Commonsense Reasoning

