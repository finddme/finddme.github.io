---
title: Investigating BERT’s Knowledge of Language:Five Analysis Methods with NPIs(Warstadt et al.(2019)
category: Natural Language Processing and Linguistics
tag: NLP & Linguistics
---
## 1. Introduction

많은 논문들에서 BERT가 어떻게 언어를 이해하는지에 대해 다루는데 본 논문에서는 BERT가 통사적 지식을 어떻게 가지는지를 평가해보고자 한다. BERT의 통사적 지식은 한가지 방법으로만 평가될 수는 없다. 따라서 크게 두 가지 방법을 통해 실험을 진행한다. 

1) negative polarity item(NPI) : NPI는 부정적인 언어환경에서 나오는 단어이다.  
2) five approaches:  
- Boolean acceptability : 문장의 참과 거짓을 판단.  
- Absolute Minimal Pair : 두 개의 문장이 있을 때 그 문장들이 단어나 미묘하게 다른 표현들을 포착할 수 있는지 실험  
- Gradient Minimal Pair : Absolute Minimal Pair에 대해 확률적으로 rough하게 봐서 일정 수준을 넘어가면 참.  
- Cloze Test : 특정 단어를 가리고 테스트.  
- Feature Probing : NPI, licensor, scope을 기준으로 문장을 학습하고 inference하는 과정  

## 2. Related Work

language representation모델이 문법적 지식을 평가하지 못하고 있다. 최근 연구들에서도 probing task, Minimal pair, Boolean acceptability judgment 등으로 평가를 시도하고 있지만 모델들의 직접적인 비교는 하지 목하고 있다. 따라서 본 논문에서는 NPI를 통해 BERT와 같은 language representation모델을 평가해보고자 한다.

### 2.1 Evaluating Sentence Encoders

Boolean classification task, Minimal pair, probing task는 BERT의 encoder 부분을 평가하는 방법들이다. 

- Boolean classification task를 통해 모델의 grammatical knowledge encoding 능력을 평가할 수 있다. 이 task의 목적은 입력된 단일 문장의 acceptability 예측하는 것이다.  
- Minimal pair를 통해 언어학적 acceptability와 하나의 요소가 다른 두 문장쌍을 비교하여 모델이 single grammatical feature를 포착하는지 판단한다.  
- Probing task는 모델의 embedding이 tense, voice, sentence length, morphological number와 같은 syntactic, surface feature들을 encoding하는지를 확인하기 위해 사용된다.   

### 2.2 Negative Polarity Items

NPI는 any처럼 부정적인 문장에서 받아들일 수 있는 단어이다. NPI는 licensor라는 환경이 구축되어야 사용될 수 있다. licensor는 일정의 언어적 환경으로, NPI를 쓰는 부정적인 환경이다. 그리고 Scope는 licensor가 미치는 영향의 범위이다. 


<center><img width="300" alt="2021-04-08 (1)" src="https://user-images.githubusercontent.com/53667002/114126626-c5739400-9933-11eb-8c3a-46b24ddcf0c4.png"></center>

예문 (1)에서 hasn’t라는 licensor가 존재하기 때문에 부정적인 단어 any가 NPI로 나올 수 있다. 그리고 이러한 licensor의 영향 하에 NPI가 나왔기 때문에 scope가 맞게 되는 것이다. 예문 (2)에는 licensor가 없기 때문에 any라는 NPI가 나왔지만 이는 허용되지 않는 쓰임으로, 비문이 된다. 예문 (3)에서는 licensor가 있지만 any라는 NLP와 scope가 맞지 않아 비문이 된다. 즉, 부정적인 환경에서 NPI가 나와야 하는데 환경 영향 범위가 시작되기 이전에 나왔기 때문에 비문이 되는 것이다. 


<center><img width="300" alt="2021-04-08" src="https://user-images.githubusercontent.com/53667002/114126659-d6240a00-9933-11eb-82ca-dc206822a90b.png"></center>


예문 (4)는 DE(down entailing)이라는 환경과 관련된 예시이다. (4)-a에서 I haven’t been to France와 I have been to Paris에서 파리는 프랑스에 속해 있기 때문에 후자가 DE환경이다. 이처럼 어떠한 범위 안에 포함된 관계일 경우, 이를 DE환경이라고 부른다. 하지만 (4)-b에서는 뒷 문장에 부정적이 표현이 들어가지 않아 DE문장이 되지 않는다. 

> DE가 부정적인 것과 어떤 관련이 있나?<br>  
최근 semantic에서 단조성(monotonicity: 한쪽 방향으로 쭉 진행되는 것)이 많이 연구되고 있다(downstream이랑 비슷한 개념이라고 생각하면 된다). 물 흘러가 듯이 cascade처럼 위에 나온 것이 참이라면 그 다음과 그 다음 다음 것도 참인 것이 되는, 단조적인 방법으로 진행되는 것을 말한다. 위 예시에서도 마찬가지로 프랑스를 간 적이 없는 것이 참이라면 파리를 간 적이 없는 것도 참인 것이다. 하지만 프랑스에 간 적이 있다해도 파리에 가지 않았을 수 있다. 따라서 a는 monotonic구조이고 b는 non-monotonic구조이다.  

NPI는 다음과 같은 문맥에서 허용된다:

- Direct negation (I haven’t seen anybody.)  
- Indirect negation (I don’t think that anybody will like this.)  
- Non-affirmative predicates (I doubt that he has done anything.)  
- Negative prepositions (They hired someone without any experience.)  
- Adversative predicates (I am surprised that anything so absurd could have been circulated.)  
- Restrictor of universal quantifier (Everyone who has any interest in linguistics…)   
- Restrictor of superlative (This is the most stupid question any person has ever asked.)  
- Comparative sentences (He was more exhausted than anyone else.)  
- Predications of ‘excess’ with too (He was too exhausted to understand anything.)  
- The protasis of a conditional clause (If you need anything, let me know.)  

> NPI는 자연언어에서 개념적으로 정의할 수는 있지만 나타나는 수많은 구성양상을 모두 설명하는 것은 불가능하다. 따라서 NPI는 언어학에서 매우 tricky한 주제이기 때문에 본 논문의 주제로 선정되었을 것이다.

### 2.3 CoLA(Corpus of Linguistic Acceptability) 

CoLA는 데이터셋이다. 본 논문은 CoLA를 기반으로 생성한 데이터를 직접 구현하여 사용한다. CoLA는 1만개 이상의 example sentence를 지니는 데이터셋이며, supervised acceptability classifier를 수행하기 위해 사용된다. 
> 한국어 NPI는 영어보다 복잡하다. 왜냐하면 한국어의 NPI가 영어보다 많기 때문이다. 영어에서는 NPI가 명확한데 한국어에서는 이게 NPI인가 싶은 것들도 NPI인 경우가 많다. 그리고 한국어 NPI는 문맥상의 의미에 따라 여러 제약이 존재한다. 한국어 NPI를 연구하여 딥러닝 모델에 적용시킬 수 있다면 좋을텐데…

## 3. Methods
본 연구는 다섯 가지 방식(Boolean acceptability, Minimal pair(Absolut, Gradient), Cloze Test, Feature probing을 통해 BERT가 NPI라는 환경에서 문법적인 지식을 이해할 수 있는지 평가한다.
앞서 본 연구에서 사용된 데이터는 CoLA를 기반으로 생성하였다는 점을 언급한 바 있다. 데이터는 한 문장과 0과 1로 구성된 Boolean label로 구성되어 있으며, Boolean label에는 크게 세 가지의 meta-data(licensor, NPI, scope) 변수들이 존재한다. meta-data의 유무에 따라 0 혹은 1의 값이 주어진다. 

<center>><img width="700" alt="2021-04-09" src="https://user-images.githubusercontent.com/53667002/114126815-1a170f00-9934-11eb-9f9c-614f40732847.png"></center>

위 표에 나타난 Licensor, NPI, Scope가 meta-data 변수이다. 

<center><img width="700" alt="2021-04-09 (1)" src="https://user-images.githubusercontent.com/53667002/114126869-2ef3a280-9934-11eb-9889-45fa643074c3.png"></center>

- Licensor  
Table 2가 Questions environment에 대한 것이니까 Table 1에서 Question부분을 보면 whether가 licensor로 주어진 것을 확인할 수 있다. 다시 Table 2를 보면 licensor whether가 온 경우에는 1이 표시되어 있고 licensor가 존재하지 않을 경우에는 that이라는 licensor replacement가 오고 0으로 표시된다.

- NPI  
Questions environment sample에서 NPI는 never이다. Table 2를 보면 NPI가 없을 경우에는 NPI replacement인 often이 오고 0으로 표시된 것을 확인할 수 있다. 

- Scope   
Scope는 Licensor가 미치는 영향이다. Table 2를 보면 Licensor whether 뒤에 대괄호가 있는데 이것이 Licensor가 미치는 영향의 범위, 즉 Scope이다. 따라서 이 범위 안에 NPI가 존재할 경우에는 Scope가 1이되고 그렇지 않을 경우에는 0이 된다. 

### 3.1 Boolean Acceptability 

Boolean Acceptability는 언어 표준에 따라 문장이 만족스러운지를 평가하는 방식이다. 해당 모델이 특정 문장에 대해 acceptable하다 혹은 unacceptable하다를 잘 판단했는지 평가하는 것이다. Boolean Acceptability 판단을 위해 fine-tuning을 진행하게 되는데, BERT같은 경우에는 마지막 layer의 [CLS] embedding 상단에 classifier를 추가시킨다. Glove Bow의 경우에는 MLP classifier에 max pooling layer를 추가하여 classifier를 생성했다. 모델의 성능은 예측된 label과 정답 값의 label을 비교하는 MCC로 측정되었다.

### 3.2 Minimal Pair

Minimal Pair(최소대립쌍)은 두 개의 문장이 있을 때 두 문장에서 딱 하나의 token만 다르게 하여 해당 쌍을 비교할 수 있도록 하는 것이다. 여기에서는 Absolute와 Gradient Minimal pair에 대해 실험이 진행된다. 

### 3.2.1 Absolute Minimal Pair

본 실험에서는 두 문장이 paradigm(세 가지 meta-data 변수의 상황) 환경 내에서 NPI와 관련된 Boolean meta-data가 하나만 다를 경우에 최소 대립쌍을 형성하게 되는데, 이때 모델이 한 가지만 다른 것을 제대로 분류할 수 있는지를 확인한다.

<center><img width="300" alt="2021-04-08 (1)" src="https://user-images.githubusercontent.com/53667002/114126927-59456000-9934-11eb-8a25-931c8a2ad7a1.png"></center>

위 예시에서 (1)은 NPI licensor가 존재하고, (2)는 존재하지 않는다. 여기에서 not이라는 것이 NPI의 Licensor가 된다.

### 3.2.2 Gradient Minimal Pair

Gradient Minimal Pair는 Absolute Minimal Pair보다 rough한 버전의 방식이다. Absolute Minimal Pair는 NPI의 위치를 통해 모델이 정확한 분류를 해내야 하지만 Gradient Minimal Pair에서는 해당 문장이 acceptable할 확률이 unacceptable할 확률보다 높으면 올바르다고 간주한다. 

## 4. Cloze Test

Cloze Test는 어떤 문장이 있을 때 중간에 한 단어를 비워 놓고 어떤 단어가 오는지 예측하는 것이다. 하지만 본 실험에서는 BERT의 Masked token에 해당하는 단어를 예측하는 방식이 아닌 해당 문장에서 masking된 부분의 위치가 어디인지 알아낼 수 있는지를 실험하였다. 

## 5. Feature Probing

Feature Probing은 meta-data를 더 세분화한 방식이다. fine-tuning 유무와 관계없이 문장의 encoder부분을 freezing시키고 그 위에 lightweight classifier를 학습시켰다. lightweight classifier란 meta-data label을 예측하기 위해 



## Reference

> Warstadt et al."Investigating BERT’s Knowledge of Language:Five Analysis Methods with NPIs,"Association for Computational Linguistics.2019
