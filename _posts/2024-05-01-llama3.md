---
title: LLaMa 3
category: Natural Language Processing
tag: NLP
---







* 목차
{:toc}










# LLaMa 3
LLaMA 3는 Meta에서 공개한 Open Source LLM model로, LLaMa2에 이어 공개된 모델이다. 
LLaMA 3는 Instruct Model과 Pre-trained Model에 대해 각각 8B, 70B 두 사이즈가 공개되었다. 

Pretraining과 Post-training 방법의 개선으로 공개된 8B, 70B의 Pretrained, Instruction-fine-tuned model이 2024 4월18일 기준 해당 parameter scale 모델 중 가장 좋은 성능을 보인다고 한다. Post-training과정에서는 false refusal rate를 줄이고, model의 alignment를 개선하고, model response의 다양성을 증가시켰다. 특히 LLaMa 3는 2보다 코드 생성, instruction 수행 능력이 크게 향상되어 모델을 보다 다양하게 활용할 수 있을 것으로 보인다. 

LLaMa 3 개발 시 Meta팀은 benchmark 성능 향상 뿐만 아니라 실제 추론 능력(real-world scenario) 최적화에도 집중하였다고 한다. 실제 추론 능력 검증을 위해 새로운 high-quality human evaluation set을 개발했다고 한다. 해당 데이터는 12가지 use case에 대한 총 1,800개 prompt로 구성되어 있다. (12가지 use case: asking for advice, brainstorming, classification, closed question answering, coding, creative writing, extraction, inhabiting a character/persona, open question answering, reasoning, rewriting, summarization). 아래 표는 해당 evaluation set에 대한 Claude Sonnet, Mistral Medium, GPT-3.5의 추론 결과를 비교한 것이다.

<center><img width="1000" src="https://github.com/finddme/finddme.github.io/assets/53667002/3a9d8f8f-20ab-4dcd-8ced-5454de03328c"></center>
<center><em style="color:gray;">https://ai.meta.com/blog/meta-llama-3/</em></center><br>


LLaMA 3 개발팀은 모델 개발 시 Model architecture, Training data, Scaling up pretraining, Instruction fine-tuning을 중점적으로 개선했다고 한다.

## Model architecture
