---
title: "KAMF : Kafka-A2A-MCP-Flink"
category: LLM / Multimodal
tag: Multimodal
---


 




* 목차
{:toc}










# AI Silo
AI Silo 문제는 Data Silo에서 파생된 개념으로 AI 모델, 데이터, 기술, 인력, 인프라 등이 부서별로 분리·고립되어 서로 연계되지 못하여 AI를 효율적으로 활용하지 못하는 현상이다. 
특히 기업에서 사용되는 ai agent들이 각각 독립적으로 운영되어 서로 통신되지 못하여 ai를 도입한 효과를 보지 못하거나 사내 데이터의 중복과 일관성 저하 문제가 발생하고 있다. 
위와 같은 문제를 완화하기 위해 KAMF stack이 주목 받고 있다.

# KAMF stack
KAMF stack은 Apache Kafka, MCP(Model Context Protocol), A2A(Agent2Agent), Apache Flink로 구성된다.
MCP로 각각의 Agent를 만들고 A2A로 Agent들끼리 소통하게 한다.

## MCP(Model Context Protocol)
MCP는 Tool 접근을 위한 프로토콜이다. LLM이 다양한 tool들과 상호작용하는 방식을 표준화하여 정의하여 agent가 자체적으로 tool들을 호출하여 사용할 수 있게 돕는다. 

MCP는 server-client-host로 구성된다.

<center><img width="500" src="https://github.com/user-attachments/assets/2f6d6778-b7e8-4d7b-8bf2-9d33302b1b17"></center>
<center><em style="color:gray;">illustrated by author</em></center><br>

- Server
  - 각각 고유의 기능을 가진 tool들 (외부 도구, 데이터 소스, 각종 기능 제공)
- Client
  - MCP server들과 연결된 interface.
  - 로컬 프로세스의 경우 표준 입출력(stdio)을 통해 이루어지고, 네트워크 서비스의 경우 HTTP와 SSE(Server-Sent Events)를 통해 이루어진다.
  - stdio 예시:
    ```python
    client = MultiServerMCPClient(
        {
            "gold_price": {
                "command": "./.venv/bin/python",
                "args": ["./mcpserver-goldprice.py"],
                "transport": "stdio",
            },
            "ledger": {
                "command": "./.venv/bin/python",
                "args": ["./mcpserver-ledger.py"],
                "transport": "stdio",
            },
            "profit_clac": {
                "command": "./.venv/bin/python",
                "args": ["./mcpserver-profitcalc.py"],
                "transport": "stdio",
            }
        }
    )
    ```

- Host
  - 사용자와 상호작용하는 app (ex. Claude Desktop)
  - client 생성 및 실행

## A2A(Agent2Agent)
A2A 서로 다른 프레임워크로 구축되고 별도 서버에서 실행되는 agent들이 효과적으로 소통하고 협업할 수 있도록 한다.

A2A를 알기 위해서는 아래 요소들에 대한 개념을 파악해야 한다.
- Agent Card
  - 각 agent들은 'Agent Card'로 각각이 어떤 기능을 수행하는 agent인지 드러낸다.
  - Agent Card는 기본적으로 /.well-known/agent.json 경로에 있다.
  - Agent Card에는 다음과 같은 정보가 포함되어야 한다.
    - `name`: 에이전트 이름
    - `description`: 에이전트 설명
    - `version`: 에이전트 버전
    - `url`: A2A 서비스 엔드포인트
    - `capabilities`: 스트리밍, 푸시 알림 등 지원 기능
    - `defaultInputModes/defaultOutputModes`: 기본 입력/출력 타입(예: text, json 등)
    - `skills`: 수행 가능한 구체적 작업 목록(각각 id, name, description, inputModes, outputModes, examples 등 포함)
    - `supportsAuthenticatedExtendedCard`: 인증 확장 카드 지원 여부(선택)
    - `securitySchemes`: 인증 방식(예: OAuth2, Bearer 등, 선택)
      
- Client Agent
  - 사용자의 요청을 받아 agent들에게 task를 할당하는 총괄 agent
  - client agent는 사용자의 요청을 받은 후 agent card를 확인하여 요청에 맞는 agent를 선정해서 해당 agent들에 task를 보낸다.
    
- Server/Remote Agent
  - 특정 기능을 수행하는 agent
  - 특정 작업을 수행하고 결과를 반환한다.
    
- Task
  - client가 agent들에게 작업을 요청하는 단위
  - `task_type`, `inputs`와 같은 필드를 포함한다.

- Artifact
  - 작업의 결과물을 담는 객체

- Status
  - 작업 진행률, 오류 등을 조회하는 endpoint

### A2A flow
1. \<Client Agent> 사용자 input 수신
2. \<Client Agent> Agent Card 불러옴
3. \<Client Agent> Agent Card를 기반으로 사용자 요청에 어떤 agent가 적합한지 점수를 매겨 호출할 agent들을 선정함
4. \<Client Agent> Task 작성해서 remote agent에 전송
5. \<Server/Remote Agent> 요청을 받아 작업을 수행




# Reference
> https://github.com/never2average/a2a-mcp-server<br>
> https://github.com/GongRzhe/A2A-MCP-Server<br>
> https://becomingahacker.org/comparing-mcp-a2a-and-agntcy-in-the-ai-agent-ecosystem-f3234b85c475<br>
> https://seanfalconer.medium.com/why-googles-agent2agent-protocol-needs-apache-kafka-507b1ec456a6<br>
> https://seanfalconer.medium.com/the-ai-silo-problem-how-data-streaming-can-unify-enterprise-ai-agents-0a138cf6398c<br>
> https://seanfalconer.medium.com/kafka-a2a-mcp-and-flink-the-new-stack-for-ai-agents-4b6cb8b85b72<br>
> https://pub.towardsai.net/a2a-mcp-langchain-powerful-agent-communication-8bb692ed51d3<br>
> https://towardsdatascience.com/inside-googles-agent2agent-a2a-protocol-teaching-ai-agents-to-talk-to-each-other/<br>
