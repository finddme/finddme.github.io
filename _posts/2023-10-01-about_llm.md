---
title: "About LLM"
category: LLM / Multimodal
tag: NLP
---







* 목차
{:toc}











대부분의 LLM은 Transformer의 Decoder 구조를 기반으로 한다.

# Transformers 요약

## Encoder and Decoder

- Encoder
  - input를 representation을 변환하는 부분. 문장을 입력 받아 언어적 특징과 의미를 vector화한다.
  - Attention
    - 모델이 입력 sequence의 모든 token들이 서로의 관계를 학습할 수 있도록 Multi-Head Self-Attention을 사용한다. 이는 모델이 각 token의 context를 이해하는데 도움을 준다.

- Decoder
  - encoding 된 representation을을 받아 모델의 출력을 생성하는 부분.
  - input
    - 학습 시에는 정답 sequence(shifted right)가 입력되고, 추론 시에는 이전에 예측된 token이 입력된다.
  - Attention
    - Masked Multi-Head Self-Attention
      - 현재 시점 이후의 token들에 대해 masking 처리를 하여 Masked Multi-Head Self-Attention을 사용한다.
      - 이와 같은 처리는 현재 시점 이전 정보만을 가지고 현재 시점의 token을 예측하도록 한다.
    - Multi-Head Attention with Encoder Output
      - Encoder의 출력(input에 대한 representation)을 받아서 input sequnece와 decoder의 input으로 입력 받은 target sequnece 간의 관계를 매핑하며 학습하도록 돕는다.
  - output
    - token별로 softmax 함수를 거쳐 (현재 시점을 기준으로 다음 token으로) 예측된 단어의 확률 분포를 산출하고 가장 높은 확률의 token을 출력한다.
 
## Attention

## Encoder-Only Models

## Decoder-Only Models

## Encoder-Decoder Models
