---
title: RAG
category: Dev Log
tag: Development
---







* 목차
{:toc}













## 1\. Dev summary

<html>
  <head>
    <style type="text/css">
      .line{border-bottom: 1px solid #BDB8C1;}
      .line2{border-bottom: 2px solid #BDB8C1;}
      .line3{border-bottom: 1px solid #BDB8C1; background-color: #F7F7F7;}
      .line4{border-bottom: 2px solid #BDB8C1; background-color: #F7F7F7;}
      table, th, td {
         border:1px solid #BDB8C1;
         background-color: #FFFFFF;
       }
    </style>
   </head>
   <body>
     <table style="border-collapse:collapse">
       <tr>
         <th class="line4" bgcolor="#F8F7F9">Project</th>
         <th class="line2">Summary of the project</th><th class="line2">Related Pages</th>
       </tr>
       <tr>
         <td class="line3"><strong>RAG + Chatbot</strong></td>
         <td class="line">
           <li>base model:
             <ul>
               <li>openai gpt-4</li>
               <li>LLaMa 2 13B</li>
             </ul>
           </li>
         </td>
         <td class="line">
           <li><a href="https://finddme.github.io/natural%20language%20processing/2023/10/10/LLMA2/">Related Paper Review (LLaMa 2)</a></li>
           <li><a href="https://finddme.github.io/natural%20language%20processing/2024/02/21/RAG/">RAG</a></li>
           <li><a href="https://finddme.github.io/natural%20language%20processing/2024/02/22/chat_history/">Chat history</a></li>
<!--            <li><a href="https://github.com/finddme/RAG">RAG with langchain Code</a></li> -->
         </td>
       </tr>
   </table>
 </body>
</html>

## 2\. Data

### 2.1 RAG data 출처 

1. 대한민국 갈등 사례(갈등 - 원인 - 이해관계자 -해결) 검색 chat을 위한 대한민국 갈등 사례 보고서 및 논문 (한국 행정 연구원으로부터 데이터 수령)
2. 대한민국 국방 관련 검색 chat을 위한 국방 보고서 및 논문 (한국 국방 연구원으로부터 데이터 수령)

### 2.2 PDF data parsing

- parsing 방식:<br>
  Rule-base parsing

- 사용 라이브러리 :<br>
  langchain.document_loaders.PyPDFDirectoryLoader

## 3\. Model

1. openai gpt-4-turbo
2. LLaMa2 -> fine tuning model ([fine-tuning log](https://finddme.github.io/dev%20log/2023/03/31/llm_tuning_merge/))
3. Mistral -> fine tuning model ([fine-tuning log](https://finddme.github.io/dev%20log/2023/03/31/llm_tuning_merge/))
4. Solar -> fine tuning model ([fine-tuning log](https://finddme.github.io/dev%20log/2023/03/31/llm_tuning_merge/))

## 4\. Chat application programming interface (API) 

- gradio (LLM tuning 결과 개인 확인용 api)
- Fastapi (협업 백엔드 개발자 선호에 맞춰 개발)
- Flask (협업 백엔드 개발자 선호에 맞춰 개발)


## 5\. Naive-RAG 이외 적용 기술

### 5.1 Pre-Retrieval

1. binary vectorstore(document type)

### 5.2 Enhanced indexing strategy

1. binary vectorstore(document type)<br>
  document type에 따라 2-3개의 vector db에 분류하여 저장
   
2. metadata filtering을 위한 Hierarchical index retrieval<br>
  chunk별 요약 결과 metadata로 저장

3. hierarchical similarity search -> 3단계<br>
  (1. query <-> document summary similarity search<br>
   2. vectorstore내에서 1번에서 검색된 document를 기반으로 similarity search (속도 향상을 위한 filtering)<br>
   3. retriever 정의 시 2번에서 검색된 document를 기반으로 similarity search)<br>

### 5.3 Retrieval
1. diverse Prompts(query type)<br>
  query type별로 다른 prompt 적용
   
### 5.4 Post-Retrieval
1. translate(en->ko)<br>
  LLM 영어 답변 반환 시 번역<br>
2. similarity-based reordering

## 6. Chat 관련 추가 기능
- return source file
- 좋아요 싫어요 버튼 추가
- [답변 일시, 소요 시간, 질문, 답변, 사용자 ip] 저장 기능 추가
- RAG 기반 질문-대답 챗 <br>
  - Weaviate의 retrieval 결과를 받아 prompt와 함께 LLM에 입력 후 결과 반환<br>
- RAG 이후 LLM 답변 시 참조된 문서 요약(source 번호 입력) <br>
  - 질의응답 내용과 참조 문서 정보를 저장하여 참조 문서 번호 입력 시 해당 문서에 대한 요약 결과 반환<br>

- 문서 제목 입력 후 문서 요약
  -문서 제목 입력 시 문서 요약 결과 반환
  - 문서 전체 길이에 따라 LLM 입력 횟수 증가+Json 형식 답변 반환
  - 표 출력을 위한 json 형식 반환
  - “표“, “json” 포함 질문 입력 시 json 형식 반환 prompt와 함께 LLM에 입력 후 결과 반환
