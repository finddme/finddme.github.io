---
title: "RAG : Query Transformation/ Query Routing"
category: LLM / Multimodal
tag: Multimodal
---







* 목차
{:toc}










# Query Transformation

## HyDE (Hypothetical Document Embedding)

## Multi/Sub query transformation

## Step-back prompting

LLM을 통해 Query가 보다 넓은 범위를 포함하도록 변경하는 방법이다. 이 방법을 통 query가 너무 구체적이고 세부적이어서 발생하는 문제를 완화할 수 있다.

```python
from langchain_core.pydantic_v1 import BaseModel, Field
from typing import Literal
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser

def step_back_prompting(query):
    prompt = ChatPromptTemplate.from_template(
        """You are an expert software engineer. 
        Your task is to rephrase the given question into a more general form that is easier to answer.
        The output should be in Korean.
        
        # Example 1
        Question: How to improve Django performance?
        Output: what factors impact web app performance?
        
        # Example 2
        Question: How to optimize browser cache in Django?
        Output: What are the different caching options?
        
        
        Question: {question}
        Output:
        """
        )
    
    # Chain
    step_back_prompt_chain = prompt | llm | StrOutputParser()
    generation = step_back_prompt_chain.invoke({"question": query})
    return generation

query="2022년부터 2023년 사이에 가장 주목 받은 LLM 모델들에 대해 설명해주세요. "
step_back_prompting(query)
```

```
output:
'최근 몇 년간 주목받은 대규모 언어 모델(LLM)들의 주요 특징과 발전 동향은 무엇인가요?'
```
## RAG-Fusion

## Decomposition

# Query Routing
